{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "6864_project_seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cicattzo/nlp_project/blob/main/6864_project_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg6-Ub-g-T5p"
      },
      "source": [
        "# Set up dependencies and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44HRJ_89fwvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ee2e31-6e86-4576-f49b-d0585a118a57"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "#MODEL_FOLDER = \"/content/drive/My Drive/mit-6864/project\"\n",
        "#!mkdir -p \"/content/drive/My Drive/mit-6864/project\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuLyWHF--mSu",
        "outputId": "1f06c686-8f24-4dea-aaa8-308c4ecdf5c0"
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/mit-6864/hw3.git\n",
        "mkdir -p /content/hw3/data"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'hw3' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTQr8nR512-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "699ab581-5d0a-4ffa-adb1-a4fc667231ed"
      },
      "source": [
        "!pip -q install transformers\n",
        "#pip install datasets==1.0.2\n",
        "!pip install sacrebleu\n",
        "!pip install rouge_score"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.3MB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 49.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 40.4MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.0MB/s \n",
            "\u001b[?25hCollecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Installing collected packages: portalocker, sacrebleu\n",
            "Successfully installed portalocker-2.0.0 sacrebleu-1.5.1\n",
            "Collecting rouge_score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (0.12.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.2.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.19.5)\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6xKHRRrczjp",
        "outputId": "02c61b34-2ce6-406c-ce46-e9b7770e5ce5"
      },
      "source": [
        "# Download data\n",
        "DATA_DIR = \"/content/hw3/data\"\n",
        "!wget -nv -O \"$DATA_DIR/vocab.en\" https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.en"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-15 19:14:39 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.en [139741/139741] -> \"/content/hw3/data/vocab.en\" [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-uskYOZjk4l"
      },
      "source": [
        "%%capture\n",
        "import sacrebleu\n",
        "from rouge_score import rouge_scorer\n",
        "import pandas as pd\n",
        "#train_ds = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train\")\n",
        "#train = pd.DataFrame(train_ds)\n",
        "#valid_ds = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"validation\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDOrHl0h2AO_",
        "outputId": "0a203f77-9dce-436f-d3bc-6daaacbf7c47"
      },
      "source": [
        "##Import Train and Test sets \n",
        "#\n",
        "train = pd.read_csv(\"/content/drive/My Drive/6864_project/train_combined.csv\")\n",
        "print(\"Training Data Shape \", train.shape)\n",
        "print(\"Training Data Columns \", train.columns)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data Shape  (14824, 3)\n",
            "Training Data Columns  Index(['article', 'highlights', 'id'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjeE69a13dVt",
        "outputId": "d6db5939-8a4a-4092-e91f-7c2ae621fb59"
      },
      "source": [
        "test = pd.read_csv(\"/content/drive/My Drive/6864_project/bc3_test.csv\")\n",
        "\n",
        "print(\"Test Data Shape \", test.shape)\n",
        "print(\"Test Data Columns \", test.columns)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Data Shape  (201, 5)\n",
            "Test Data Columns  Index(['listno', 'subject', 'body', 'email_num', 'summary'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olW8jrSH4UZv"
      },
      "source": [
        "#Naming convention to be followed - articles, highlights\n",
        "test = test[[\"body\", \"summary\"]]\n",
        "test.columns = [\"article\", \"highlights\"]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34DQNht6lAr5",
        "outputId": "4fe72bd3-7638-4d99-fd87-e6347d55f18a"
      },
      "source": [
        "#Get sentence lengths for training data set summaries and articles \n",
        "train[\"len\"] = train[\"article\"].apply(lambda x : len(x.split()))\n",
        "train[\"sumlen\"] = train[\"highlights\"].apply(lambda x : len(x.split()))\n",
        "print(\"Max sentence length for training dataset articles is \", max(train[\"len\"]))\n",
        "print(\"Max sentence length for training dataset summaries is \", max(train[\"sumlen\"]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length for training dataset articles is  1876\n",
            "Max sentence length for training dataset summaries is  121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThwVHHpgojY1",
        "outputId": "5b9d00dd-1f14-4329-b47d-4c748a8270ff"
      },
      "source": [
        "#Get sentence lengths for training data set summaries and articles \n",
        "test[\"len\"] = test[\"article\"].apply(lambda x : len(x.split()))\n",
        "test[\"sumlen\"] = test[\"highlights\"].apply(lambda x : len(x.split()))\n",
        "print(\"Max sentence length for test dataset articles is \", max(test[\"len\"]))\n",
        "print(\"Max sentence length for test dataset summaries is \", max(test[\"sumlen\"]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length for test dataset articles is  451\n",
            "Max sentence length for test dataset summaries is  73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "Uvusiorn5jZO",
        "outputId": "44e23c22-4bcc-4b19-851b-836a9dffe4f7"
      },
      "source": [
        "#Plot ditributions for article and summary lengths in the training dataset\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "%matplotlib inline\n",
        "fig= sns.histplot(train[\"len\"])\n",
        "fig.set(xlabel='Article Length - Training Data')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "B5-1btr66zrP",
        "outputId": "1172f956-b2f4-414b-818c-9e62d8f56af6"
      },
      "source": [
        "sns.set()\n",
        "%matplotlib inline\n",
        "fig= sns.histplot(test[\"len\"])\n",
        "fig.set(xlabel='Article Length - Test Data')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "g317_e4Q7HbC",
        "outputId": "acf65e94-8529-4b0d-dd77-36b7b51883e8"
      },
      "source": [
        "#Plot ditributions for article and summary lengths in the training dataset\n",
        "#import seaborn as sns\n",
        "sns.set()\n",
        "%matplotlib inline\n",
        "fig= sns.histplot(train[\"sumlen\"])\n",
        "fig.set(xlabel='Summary Length - Training Data')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "cLeOOJj87NT1",
        "outputId": "99a21974-bf94-4b8a-9e6b-761aa452a2d8"
      },
      "source": [
        "sns.set()\n",
        "%matplotlib inline\n",
        "fig= sns.histplot(test[\"sumlen\"])\n",
        "fig.set(xlabel='Summary Length - Test Data')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flCBSHHJ7NLI",
        "outputId": "df3bc598-a9aa-4380-8494-d4091b674bd0"
      },
      "source": [
        "#Select max sentence length \n",
        "train = train.query('len < 400 and sumlen < 400 and len >0 and sumlen >0')\n",
        "test = test.query('len < 400 and sumlen < 400 and len >0 and sumlen >0')\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4358, 5)\n",
            "(198, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "CE99sNVEmp5z",
        "outputId": "4e48746e-071a-4eb4-a423-b3287f0a1395"
      },
      "source": [
        "#Uncomment to save dataframes \n",
        "#from google.colab import files\n",
        "#train.to_csv('short_cnn.csv') \n",
        "#files.download('short_cnn.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_99e9d417-62cc-440e-a025-684f593f0a1f\", \"short_cnn.csv\", 13211282)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV1H7hrZ-zgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf93f65c-4d20-4dd0-adc0-aa29b21c27dc"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/hw3\")\n",
        "import pandas as pd\n",
        "import lab_utils\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import torch \n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "assert device == \"cuda\"   # use gpu whenever you can!\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "#torch.cuda.empty_cache()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdhEWOBR9NxS",
        "outputId": "c58329e5-a4f2-447e-b898-4cdbc8c12eb5"
      },
      "source": [
        "#Preprocessing \n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i_tRdf3-2Lg"
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hN3sKaN-Xe_",
        "outputId": "e29bc07c-d4e6-48fb-eab0-f60de25e248f"
      },
      "source": [
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower() \n",
        "    text = text.split() \n",
        "    for i in range(len(text)):\n",
        "        word = text[i]\n",
        "        if word in contraction_mapping:\n",
        "            text[i] = contraction_mapping[word]\n",
        "    text = \" \".join(text)\n",
        "    text = text.split()\n",
        "    newtext = []\n",
        "    for word in text:\n",
        "        if word not in stop_words:\n",
        "            newtext.append(word)\n",
        "    text = \" \".join(newtext)\n",
        "    text = text.replace(\"'s\",'') \n",
        "    text = re.sub(r'\\(.*\\)','',text) # remove (words)\n",
        "    text = re.sub(r'[^a-zA-Z. ]','',text) # remove punctuations but not full stop\n",
        "    text = re.sub(r'\\&','',text)  #Found very often in CNN dataset \n",
        "    text = re.sub(r'(cnn)|(new :)|(news :)','',text)\n",
        "    text = re.sub(r' +',' ',text)\n",
        "    return text\n",
        "print(preprocess(\"123 kjenkdnwkjef jksdbkj wjdkjsd,cdnj....\"))\n",
        "print(\"123 kjenkdnwkjef jksdbkj wjdkjsd,cdnj....\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " kjenkdnwkjef jksdbkj wjdkjsdcdnj....\n",
            "123 kjenkdnwkjef jksdbkj wjdkjsd,cdnj....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF_IVvBWZbzx"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Piy00o2l9h"
      },
      "source": [
        "def convert_token_list(df, column):\n",
        "  ## regex replace multiple occurences of - , > , < and covert .com to website \n",
        "  ts = df[column].values.tolist()\n",
        "  tst =[]\n",
        "  for i in range(df.shape[0]):\n",
        "    tokens = word_tokenize(ts[i])\n",
        "    tokens_stem=[]\n",
        "    for word in tokens:\n",
        "      wordt = ps.stem(word)\n",
        "      tokens_stem.append(wordt)\n",
        "    tst.append(tokens_stem)\n",
        "  return tst "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j49BSaMMAvh7"
      },
      "source": [
        "train.loc[:,'highlights'] = train['highlights'].apply(lambda x:preprocess(x))\n",
        "train.loc[:,'article'] = train['article'].apply(lambda x:preprocess(x))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DZq878BBCyR"
      },
      "source": [
        "test.loc[:,'highlights'] = test['highlights'].apply(lambda x:preprocess(x))\n",
        "test.loc[:,'article'] = test['article'].apply(lambda x:preprocess(x))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgMmXniCDkPc"
      },
      "source": [
        "train_src_sentences_list = convert_token_list(train, \"article\")\n",
        "train_trg_sentences_list = convert_token_list(train, \"highlights\")\n",
        "assert len(train_src_sentences_list) == len(train_trg_sentences_list)\n",
        "\n",
        "test_src_sentences_list = convert_token_list(test, \"article\")\n",
        "test_trg_sentences_list = convert_token_list(test, \"highlights\")\n",
        "assert len(test_src_sentences_list) == len(test_trg_sentences_list)\n",
        "\n",
        "MAX_SENT_LENGTH = 400\n",
        "MAX_SENT_LENGTH_PLUS_SOS_EOS = MAX_SENT_LENGTH +2 "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ALviY16dJpS",
        "outputId": "ab7ccbd2-907e-426e-ccef-2415502caa98"
      },
      "source": [
        "from lab_utils import read_vocab_file, read_sentence_file, filter_data\n",
        "src_vocab = read_vocab_file(\"vocab.en\")\n",
        "print(\"Default vocab size \", len(src_vocab))\n",
        "def_vocab = src_vocab[0:5]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default vocab size  17192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsG_a35OEIo0",
        "outputId": "cd1fbe10-662e-4614-fac5-57d9f14c5216"
      },
      "source": [
        "src_vocab_set = def_vocab + list(set([i for j in train_src_sentences_list for i in j] + [i for j in train_trg_sentences_list for i in j]))\n",
        "trg_vocab_set = src_vocab_set\n",
        "print(\"Custom vocab size \", len(src_vocab_set))\n",
        "#The size of this custom vocab is much higher than the default one. We will choose this one to avoid unk tokens "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Custom vocab size  30972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bah0S5rKTDT9"
      },
      "source": [
        "\n",
        "train_src_sentences_list, train_trg_sentences_list = filter_data(\n",
        "    train_src_sentences_list, train_trg_sentences_list, MAX_SENT_LENGTH)\n",
        "test_src_sentences_list, test_trg_sentences_list = filter_data(\n",
        "    test_src_sentences_list, test_trg_sentences_list, MAX_SENT_LENGTH)\n",
        "\n",
        "# We take 10% of training data as validation set.\n",
        "num_val = int(len(train_src_sentences_list) * 0.1)\n",
        "val_src_sentences_list = train_src_sentences_list[:num_val]\n",
        "val_trg_sentences_list = train_trg_sentences_list[:num_val]\n",
        "train_src_sentences_list = train_src_sentences_list[num_val:]\n",
        "train_trg_sentences_list = train_trg_sentences_list[num_val:]\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOjSiD3urw_R"
      },
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "\n",
        "# These IDs are reserved.\n",
        "PAD_INDEX = 0\n",
        "UNK_INDEX = 1\n",
        "SOS_INDEX = 2\n",
        "EOS_INDEX = 3\n",
        "\n",
        "\n",
        "class MTDataset(data.Dataset):\n",
        "  def __init__(self, src_sentences, src_vocabs, trg_sentences, trg_vocabs,\n",
        "               sampling=1.):\n",
        "    self.src_sentences = src_sentences[:int(len(src_sentences) * sampling)]\n",
        "    self.trg_sentences = trg_sentences[:int(len(src_sentences) * sampling)]\n",
        "\n",
        "    self.max_src_seq_length = MAX_SENT_LENGTH_PLUS_SOS_EOS\n",
        "    self.max_trg_seq_length = MAX_SENT_LENGTH_PLUS_SOS_EOS\n",
        "\n",
        "    self.src_vocabs = src_vocabs\n",
        "    self.trg_vocabs = trg_vocabs\n",
        "\n",
        "    self.src_v2id = {v : i for i, v in enumerate(src_vocabs)}\n",
        "    self.src_id2v = {val : key for key, val in self.src_v2id.items()}\n",
        "    self.trg_v2id = {v : i for i, v in enumerate(trg_vocabs)}\n",
        "    self.trg_id2v = {val : key for key, val in self.trg_v2id.items()}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.src_sentences)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    src_sent = self.src_sentences[index]\n",
        "    src_len = len(src_sent) + 2   # add <s> and </s> to each sentence\n",
        "    src_id = []\n",
        "    for w in src_sent:\n",
        "      if w not in self.src_vocabs:\n",
        "        #print(w)\n",
        "        w = '<unk>'\n",
        "      src_id.append(self.src_v2id[w])\n",
        "    src_id = ([SOS_INDEX] + src_id + [EOS_INDEX] + [PAD_INDEX] *\n",
        "              (self.max_src_seq_length - src_len))\n",
        "\n",
        "    trg_sent = self.trg_sentences[index]\n",
        "    trg_len = len(trg_sent) + 2\n",
        "    trg_id = []\n",
        "    for w in trg_sent:\n",
        "      if w not in self.trg_vocabs:\n",
        "        w = '<unk>'\n",
        "      trg_id.append(self.trg_v2id[w])\n",
        "    trg_id = ([SOS_INDEX] + trg_id + [EOS_INDEX] + [PAD_INDEX] *\n",
        "              (self.max_trg_seq_length - trg_len))\n",
        "\n",
        "    return torch.tensor(src_id), src_len, torch.tensor(trg_id), trg_len"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAk-fj8GEdOj"
      },
      "source": [
        "Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ3rJ1TlElu5"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, dropout=0.):    \n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.rnn = nn.GRU(input_size, hidden_size, num_layers=3, batch_first=True,\n",
        "                      dropout=dropout, bidirectional=True)\n",
        "\n",
        "  def forward(self, inputs, lengths):\n",
        "    outputs = None\n",
        "    finals = None\n",
        "    #embeddings = self.dropout(self.embedding(x))\n",
        "    \n",
        "    packed = pack_padded_sequence(inputs, lengths.cpu(), batch_first=True,\n",
        "                                  enforce_sorted=False)\n",
        "    outputs, finals = self.rnn(packed)\n",
        "    outputs, _ = pad_packed_sequence(outputs, batch_first=True,\n",
        "                                     total_length=MAX_SENT_LENGTH_PLUS_SOS_EOS)\n",
        "\n",
        "    return outputs, finals"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCTTreYNFMja"
      },
      "source": [
        "## Decoder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZnDk1j9FNOH"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  \"\"\"An RNN decoder without attention.\"\"\"\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, dropout=0.):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    \n",
        "    self.rnn = nn.GRU(input_size, hidden_size, batch_first=True,\n",
        "                      dropout=dropout)\n",
        "    self.bridge = nn.Linear(hidden_size, hidden_size, bias=True)\n",
        "\n",
        "    self.dropout_layer = nn.Dropout(p=dropout)\n",
        "    self.pre_output_layer = nn.Linear(hidden_size + input_size, hidden_size,\n",
        "                                      bias=False)\n",
        "    \n",
        "\n",
        "  def forward_step(self, prev_embed, hidden):\n",
        "\n",
        "    pre_output = None\n",
        "\n",
        "    pre_output, hidden = self.rnn(prev_embed, hidden) # minimun necessary\n",
        "\n",
        "    pre_output = torch.cat([prev_embed, pre_output], dim=2)\n",
        "\n",
        "    pre_output = self.dropout_layer(pre_output)\n",
        "    pre_output = self.pre_output_layer(pre_output)\n",
        "\n",
        "    return hidden, pre_output\n",
        "\n",
        "  def forward(self, inputs, encoder_finals, hidden=None, max_len=None):\n",
        "\n",
        "    if max_len is None:\n",
        "      max_len = inputs.size(1)\n",
        "\n",
        "    if hidden is None:\n",
        "      hidden = self.init_hidden(encoder_finals)\n",
        "\n",
        "    outputs = None\n",
        "\n",
        "    pre_output_vectors = []\n",
        "\n",
        "    for i in range(max_len):\n",
        "      prev_embed = inputs[:, i].unsqueeze(1)\n",
        "      hidden, pre_output = self.forward_step(prev_embed, hidden)\n",
        "      pre_output_vectors.append(pre_output)\n",
        "\n",
        "    outputs = torch.cat(pre_output_vectors, dim=1)\n",
        "\n",
        "    return hidden, outputs\n",
        "\n",
        "  def init_hidden(self, encoder_finals):\n",
        "    \"\"\"Use encoder final hidden state to initialize decoder's first hidden\n",
        "    state.\"\"\"\n",
        "    decoder_init_hiddens = torch.tanh(self.bridge(encoder_finals))\n",
        "    \n",
        "    return decoder_init_hiddens"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPmfDZ2fF7jy"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "  \"\"\"A standard Encoder-Decoder architecture without attention.\n",
        "  \"\"\"\n",
        "  def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
        "    super(EncoderDecoder, self).__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_embed = src_embed\n",
        "    self.trg_embed = trg_embed\n",
        "    self.generator = generator\n",
        "\n",
        "  def forward(self, src_ids, trg_ids, src_lengths):\n",
        "    encoder_hiddens, encoder_finals = self.encode(src_ids, src_lengths)\n",
        "    del encoder_hiddens   # unused\n",
        "    return self.decode(encoder_finals, trg_ids[:, :-1])\n",
        "\n",
        "  def encode(self, src_ids, src_lengths):\n",
        "    return self.encoder(self.src_embed(src_ids), src_lengths)\n",
        "    \n",
        "  def decode(self, encoder_finals, trg_ids, decoder_hidden=None):\n",
        "    return self.decoder(self.trg_embed(trg_ids), encoder_finals, decoder_hidden)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T43dUgwLGBnI"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
        "  def __init__(self, hidden_size, vocab_size):\n",
        "    super(Generator, self).__init__()\n",
        "    self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return F.log_softmax(self.proj(x), dim=-1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdfQQaXgHcX_"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx_PXmw3HgXo"
      },
      "source": [
        "from torch.utils import data\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_set = MTDataset(train_src_sentences_list, src_vocab_set,\n",
        "                      train_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "train_data_loader = data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                    num_workers=3, shuffle=True)\n",
        "val_set = MTDataset(val_src_sentences_list, src_vocab_set,\n",
        "                    val_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "val_data_loader = data.DataLoader(val_set, batch_size=batch_size, num_workers=3,\n",
        "                                  shuffle=False)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIrMBzl7HswK"
      },
      "source": [
        "import math\n",
        "\n",
        "\n",
        "class SimpleLossCompute:\n",
        "  \"\"\"A simple loss compute and train function.\"\"\"\n",
        "\n",
        "  def __init__(self, generator, criterion, opt=None):\n",
        "    self.generator = generator\n",
        "    self.criterion = criterion\n",
        "    self.opt = opt\n",
        "\n",
        "  def __call__(self, x, y, norm):\n",
        "    x = self.generator(x)\n",
        "    loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
        "                          y.contiguous().view(-1))\n",
        "    loss = loss / norm\n",
        "\n",
        "    if self.opt is not None:  # training mode\n",
        "      loss.backward()          \n",
        "      self.opt.step()\n",
        "      self.opt.zero_grad()\n",
        "\n",
        "    return loss.data.item()*norm\n",
        "loss_fct =[]\n",
        "def run_epoch(data_loader, model, loss_compute, print_every):\n",
        "  \"\"\"Standard Training and Logging Function\"\"\"\n",
        "\n",
        "  total_tokens = 0\n",
        "  total_loss = 0\n",
        "\n",
        "  for i, (src_ids_BxT, src_lengths_B, trg_ids_BxL, trg_lengths_B) in enumerate(data_loader):\n",
        "\n",
        "    src_ids_BxT = src_ids_BxT.to(device)\n",
        "    src_lengths_B = src_lengths_B.to(device)\n",
        "    trg_ids_BxL = trg_ids_BxL.to(device)\n",
        "\n",
        "    del trg_lengths_B   # unused\n",
        "\n",
        "    _, output = model(src_ids_BxT, trg_ids_BxL, src_lengths_B)\n",
        "\n",
        "    loss = loss_compute(x=output, y=trg_ids_BxL[:, 1:],\n",
        "                        norm=src_ids_BxT.size(0))\n",
        "    total_loss += loss\n",
        "    total_tokens += (trg_ids_BxL[:, 1:] != PAD_INDEX).data.sum().item()\n",
        "\n",
        "    if model.training and i % print_every == 0:\n",
        "      print(\"Epoch Step: %d Loss: %f\" % (i, loss / src_ids_BxT.size(0)))\n",
        "      loss_fct.append(loss / src_ids_BxT.size(0))\n",
        "\n",
        "  return  loss/src_ids_BxT.size(0), math.exp(total_loss / float(total_tokens))\n",
        "\n",
        "\n",
        "def train(model, num_epochs, learning_rate, print_every):\n",
        "  criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
        "  optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Keep track of dev ppl for each epoch.\n",
        "  dev_ppls = []\n",
        "  losses =[]\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print(\"Epoch\", epoch)\n",
        "\n",
        "    model.train()\n",
        "    loss, train_ppl = run_epoch(data_loader=train_data_loader, model=model,\n",
        "                          loss_compute=SimpleLossCompute(model.generator,\n",
        "                                                         criterion, optim),\n",
        "                          print_every=print_every)\n",
        "        \n",
        "    model.eval()\n",
        "    with torch.no_grad():      \n",
        "      loss, dev_ppl = run_epoch(data_loader=val_data_loader, model=model,\n",
        "                          loss_compute=SimpleLossCompute(model.generator,\n",
        "                                                         criterion, None),\n",
        "                          print_every=print_every)\n",
        "      print(\"Validation perplexity: %f\" % dev_ppl)\n",
        "      dev_ppls.append(dev_ppl)\n",
        "      losses.append(loss)\n",
        "        \n",
        "  return  dev_ppls"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKJI-SpsHPTY"
      },
      "source": [
        "### EncoderDecoder Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntwQRFWe7-CA"
      },
      "source": [
        "# Hyperparameters for contructing the encoder-decoder model.\n",
        "embed_size = 300   \n",
        "hidden_size = 256  \n",
        "dropout = 0.3\n",
        "\n",
        "pure_seq2seq = EncoderDecoder(\n",
        "    encoder=Encoder(embed_size, hidden_size, dropout=dropout),\n",
        "    decoder=Decoder(embed_size, hidden_size, dropout=dropout),\n",
        "    src_embed=nn.Embedding(len(src_vocab_set), embed_size),\n",
        "    trg_embed=nn.Embedding(len(trg_vocab_set), embed_size),\n",
        "    generator=Generator(hidden_size, len(trg_vocab_set))).to(device)\n",
        "\n",
        "train_model = True\n",
        "if train_model:\n",
        "  losses, pure_dev_ppls = train(pure_seq2seq, num_epochs= 10, learning_rate=1e-3, print_every=500)\n",
        "  torch.save(pure_seq2seq.state_dict(), MODEL_FOLDER+\"/\" + \"pure_seq2seq.pt\")\n",
        "else:\n",
        "  pure_seq2seq.load_state_dict(torch.load(MODEL_FOLDER+\"/\" + \"pure_seq2seq.pt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-USDXtE_5fVJ"
      },
      "source": [
        "path = \"/content/drive/My Drive/6864_project/van_seqseq.pth\"\n",
        "#load trained model or save a new model\n",
        "pure_seq2seq = torch.load(path)\n",
        "#torch.save(pure_seq2seq, path)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlAJiAeuH-H4"
      },
      "source": [
        "Decoding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPAdZCwbsFJV"
      },
      "source": [
        "def greedy_decode(model, src_ids, src_lengths, max_len):\n",
        "\n",
        "  with torch.no_grad():\n",
        "    _, encoder_finals = model.encode(src_ids, src_lengths)\n",
        "    prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(src_ids)\n",
        "\n",
        "  output = []\n",
        "  hidden = None\n",
        "  \n",
        "  for i in range(max_len):\n",
        "    with torch.no_grad():\n",
        "      hidden, outputs = model.decode(encoder_finals, prev_y, hidden)\n",
        "      prob = model.generator(outputs[:, -1])\n",
        "    d, next_word = torch.max(prob, dim=1)\n",
        "    next_word = next_word.data.item()\n",
        "    output.append(next_word)\n",
        "    prev_y = torch.ones(1, 1).type_as(src_ids).fill_(next_word)\n",
        "\n",
        "  output = np.array(output)\n",
        "\n",
        "  # Cut off everything starting from </s>.\n",
        "  first_eos = np.where(output == EOS_INDEX)[0]\n",
        "  if len(first_eos) > 0:\n",
        "    output = output[:first_eos[0]]\n",
        "  return output"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KK3XV1iDnoX"
      },
      "source": [
        "def beam_decode(model, src_ids, src_lengths, max_len):\n",
        "\n",
        "  with torch.no_grad():\n",
        "    _, encoder_finals = model.encode(src_ids, src_lengths)\n",
        "    prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(src_ids)\n",
        "\n",
        "  output = []\n",
        "  hidden = None\n",
        "  for i in range(max_len):\n",
        "    with torch.no_grad():\n",
        "      hidden, outputs = model.decode(encoder_finals, prev_y, hidden)\n",
        "      prob = model.generator(outputs[:, -1])\n",
        "    d, next_word = torch.max(prob, dim=1)\n",
        "    next_word = next_word.data.item()\n",
        "    output.append(next_word)\n",
        "    prev_y = torch.ones(1, 1).type_as(src_ids).fill_(next_word)\n",
        "\n",
        "  output = np.array(output)\n",
        "\n",
        "  # Cut off everything starting from </s>.\n",
        "  first_eos = np.where(output == EOS_INDEX)[0]\n",
        "  if len(first_eos) > 0:\n",
        "    output = output[:first_eos[0]]\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdqZeB2VKl6T"
      },
      "source": [
        "def print_examples(model, src_vocab_set, trg_vocab_set, data_loader, decoder, \n",
        "                   with_attention=False, n=3, EOS_INDEX=3, max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS):\n",
        "  \"\"\"Prints `n` examples. Assumes batch size of 1.\"\"\"\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  for i, (src_ids, src_lengths, trg_ids, _) in enumerate(data_loader):\n",
        "    if not with_attention:\n",
        "      result = decoder(model, src_ids.to(device), src_lengths.to(device),\n",
        "                             max_len=max_len)\n",
        "    else:\n",
        "      result, _ = decoder(model, src_ids.to(device),\n",
        "                                          src_lengths.to(device),\n",
        "                                          max_len=max_len)\n",
        "\n",
        "    # remove <s>\n",
        "    src_ids = src_ids[0, 1:]\n",
        "    trg_ids = trg_ids[0, 1:]\n",
        "    # remove </s> and <pad>\n",
        "    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
        "    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
        "  \n",
        "    print(\"Example #%d\" % (i + 1))\n",
        "    print(\"Src : \", \" \".join(lookup_words(src_ids, vocab=src_vocab_set)))\n",
        "    print(\"Trg : \", \" \".join(lookup_words(trg_ids, vocab=trg_vocab_set)))\n",
        "    print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab_set)))\n",
        "    print()\n",
        "\n",
        "    if i == n - 1:\n",
        "      break"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTf85UwmJlWA",
        "outputId": "1a289d9c-5933-4510-857d-564e93ab8833"
      },
      "source": [
        "example_set = MTDataset(val_src_sentences_list, src_vocab_set,\n",
        "                        val_trg_sentences_list, trg_vocab_set)\n",
        "example_data_loader = data.DataLoader(example_set, batch_size=1, num_workers=1,\n",
        "                                      shuffle=False)\n",
        "\n",
        "print(\"EncoderDecoder Results:\")\n",
        "lab_utils.print_examples(pure_seq2seq, src_vocab_set, trg_vocab_set,\n",
        "                         example_data_loader, greedy_decode, n= 10)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EncoderDecoder Results:\n",
            "Example #1\n",
            "Src :  polic arrest anoth teen thursday sixth suspect jail connect gang rape yearold girl northern california high school campu . jose carlo montano arrest charg feloni rape rape concert forc penetr foreign object said richmond polic lt. mark gagan . montano arrest thursday even san pablo california small town two mile citi richmond crime took place . montano held lieu . million bail accus take part polic said hour assault richmond high school campu . polic said mani peopl involv rape dimli lit back alley school anoth peopl watch without call . victim taken hospit critic condit releas wednesday . four teenag suspect arraign thursday charg connect rape . codi ray smith describ court older plead guilti charg rape foreign object rape forc . two juvenil ari abdallah moral marcel jame peter appear smith contra costa counti superior court enter plea . court describ moral younger give age peter . three juvenil wore bulletproof vest hear charg adult . fourth person manuel ortega appear separ without attorney enter plea . wear protect vest . anoth person salvador rodriguez arrest tuesday night court thursday .\n",
            "Trg :  anoth arrest made gang rape outsid california school . investig say peopl took part stood watch assault . four suspect appear court thursday three wore bulletproof vest .\n",
            "Pred:  herd alert wavi dorschner energysav riecken dorrin stadia miscarri dachshund piotr cuisin stadia\n",
            "\n",
            "Example #2\n",
            "Src :  seven world entertain airport . boe final batteri test dreamlin . faa delay closur control tower .\n",
            "Trg :  hawaiian airlin land no . ontim perform . airlin qualiti rank report look largest u.s. airlin . expressjet american airlin worst ontim perform . virgin america best baggag handl southwest lowest complaint rate .\n",
            "Pred:  puttin mauri paranavitana laviani strand start watersid nonurg rfi stadia\n",
            "\n",
            "Example #3\n",
            "Src :  tripoli libya rebel tripoli furious hunt sign longtim libyan leader moammar gadhafi explor network tunnel bunker built beneath massiv compound . sara sidner got peek passageway friday . dub gadhafi inner sanctum . correspond cover battl tripoli walk step pitchdark tunnel use flashlight navig underworld describ massiv . far said rebel clear meter underground passag . tunnel network believ extend way citi intern airport rixo hotel . journalist two foreign nation held five day progadhafi forc . also thought extend neighborhood gadhafi forc lob shell recent toward compound taken rebel . tunnel sidner saw wide enough adult walk side side . spot golf cart easili fit corridor . sidner also saw rang sight stroll labyrinth thick wall massiv door sturdi lock . char ceil couch bed fire appar occur . piec metal shrapnel . section nato bomb fell roof cave in . anoth room contain videotap line shelf part tv studio gadhafi may record messag . it set like surviv bunker sidner said onair report . there liter citi here .\n",
            "Trg :  sara sidner see anoth world tunnel tripoli . gadhafi may record tape messag studio . rebel method search wind passag .\n",
            "Pred:  yewtre osmar mortarzavi lowspe earlier crocker sediment jfk multityp stadia puttin rudisha yemenibas fakarul wavi gervinho stadia\n",
            "\n",
            "Example #4\n",
            "Src :  german tourist critic condit shark sever right arm snorkel hawaii wednesday author said . approxim yearold woman unconsci first respond arriv taken maui medic center treatment accord lee mainaga maui fire depart . shark found new york subway car . attack took place yard offshor white rock beach maui . beach close one mile either side attack happen . offici assess thursday morn whether beach reopen . shark attack claim brazilian teen life . shark attack fourth maui year two happen day februari late juli . shark attack uptick recent year accord univers florida fatal rate unit state . discoveri channel defend dramat shark special . best place swim shark .\n",
            "Trg :  fourth shark attack maui year . took place yard offshor . offici decid thursday beach reopen .\n",
            "Pred:  herd alert nsa marathon leuenhagen sylar rightlean stadia puttin lula mate inflammatori spontan inflammatori stomach drench stadia\n",
            "\n",
            "Example #5\n",
            "Src :  fifteen peopl die consum cantaloup contamin listeria monocytogen bacteria center diseas control prevent said friday . least peopl state becom ill bacteria agenc said . number ill could still grow ad cdc cite report lag diseas develop slowli peopl . tuesday cdc report death ill alreadi deadliest foodborn ill outbreak unit state sinc . five peopl die new mexico eat taint cantaloup cdc said . three peopl die colorado two texa one kansa maryland missouri nebraska oklahoma . ill also report alabama arkansa california illinoi indiana montana north dakota virginia west virginia wisconsin wyom . need know listeria . fell ill year old cdc said . doctor also close monitor pregnanc two women ate contamin cantaloup agenc note listeriosi caus miscarriag stillbirth . older adult peopl compromis immun system also especi suscept . public health investig trace sourc bacteria farm granada colorado . food poison . grower jensen farm issu recal rocki fordbrand cantaloup septemb . now cantaloup store shelv cdc said . agenc warn peopl eat rocki ford cantaloup even eaten part one yet fallen ill. also said consum wari eat cantaloup know came from . keep food safe .\n",
            "Trg :  contamin cantaloup caus ill state cdc say . addit death total peopl fallen ill agenc say . fruit thought taint listeria monocytogen bacteria . coloradobas jensen farm recal cantaloup .\n",
            "Pred:  seba contempor anbar naypidaw throwback stadia rainer towboat whoop return kobani closeair warmiss stadia\n",
            "\n",
            "Example #6\n",
            "Src :  chri meloni book first postsvu gig bloodi good one . former star dick wolf drama join hbo true blood season ancient power vampir hold fate bill eric hand . seri regular . meloni role alan ball drama mark homecom sort actor previous play chri keller pay cabler gritti drama oz . earlier year meloni decid step play detect elliot stabler longrun nbc drama . see full articl ew.com . click tri risk free issu entertain weekli . entertain weekli time inc. right reserv .\n",
            "Trg :  christoph meloni join hbo true blood season . play ancient power vampir hold fate bill eric hand actor previous play chri keller pay cabler gritti drama oz\n",
            "Pred:  demjanjuk immin secondbest intim lingo aw stadia macintosh exclud nsa stadia\n",
            "\n",
            "Example #7\n",
            "Src :  if car park harvard yard rockin school offici may soon come knockin hankypanki student faculti elit univers offici ban . specif school adopt new polici week prohibit romant relationship undergradu professor . previou polici professor student taught . harvard releas statement say special appoint committe determin exist languag relationship unequ statu explicitli reflect faculti expect constitut appropri relationship undergradu student faculti member ... therefor committe revis polici includ clear prohibit better accord expect . action come nearli year u.s. depart educ announc investig colleg univers includ harvard violat pertain titl ix feder law prohibit sex discrimin colleg campus . harvard respond time say appoint first ever titl ix offic school presid recent announc creation universitywid task forc compos faculti student staff recommend better prevent sexual misconduct harvard . new polici result a formal process review harvard univers titl ix polici school said .\n",
            "Trg :  harvard ban romant relationship professor student . polici come heel investig titl ix violat .\n",
            "Pred:  muller ecosystem masipa outpour inquiri deadey speight stadia sunnirul pier yewtre osmar mortarzavi asianamerican hallgrimskirkja testfir stadia\n",
            "\n",
            "Example #8\n",
            "Src :  libyan deputi foreign minist abdelati obeidi flew greec sunday deliv person messag libyan leader moammar gadhafi greek foreign ministri offici told . libya ask greec allow special envoy travel commun messag greek foreign ministri spokesman grigori delavekoura said . natur messag immedi known . obeidi met greek prime minist georg papandr sunday night accord greek foreign minist dimitri droutsa . we stress reiter clear messag intern commun . one full support implement decis unit nation immedi ceasefir end violenc particularli libyan civilian droutsa said meet . from libyan envoy said clear administr look solut ad . obeidi expect continu talk turkey malta accord droutsa . envoy cross libyan border tunisia sunday morn board privat greek plane athen . obeidi libyan deputi foreign minist charg european affair . journalist houda zaghdoudi elinda labropoul contribut report .\n",
            "Trg :  new libya deputi foreign minist european affair meet greek prime minist . new envoy expect continu talk turkey malta greek offici say . it clear administr look solut\n",
            "Pred:  offpeak sudanes naypidaw eglin naypidaw eglin stadia parti ervan proofoflif precedentset pst stadia\n",
            "\n",
            "Example #9\n",
            "Src :  hong kong thousand peopl fill hong kong victoria park saturday mark nd anniversari bloodi crackdown prodemocraci protest tiananmen squar . candlelight vigil come recent effort chines govern quash wouldb demonstr hold antigovern protest . peopl arrest februari march accord hong kongbas human right group anonym group began internet campaign call antigovern protest china similar one taken hold middl east . respons campaign author deploy heavi secur along major thoroughfar especi wangfuj busi shop street downtown beij design onlin group protest . govern also tighten rule foreign report explicitli warn risk detent suspens press card expuls show plan demonstr . year on tiananmen rememb . saturday protest annual event organ hong kong allianc prodemocraci group . hong kong polic call peac gather . imag demonstr show sea flicker candl cover length park . littl year ago student gather tiananmen squar memori recent deceas hu yaobang . fire communist parti chief deng xiaop push polici deem soft toward bourgeoisliber idea toler student protest . april memori quickli turn prodemocraci movement student held talk govern later hunger strike tiananmen squar press caus . june chines troop armor personnel carrier tank rumbl toward tiananmen squar . soldier strict order clear squar demonstr forc way citi main thoroughfar . along way met fierc resist student citi resid barricad street fire them . fire stop hundr thousand peopl lay maim dead . rel victim renew hope everi year beij leader revers verdict protest counterrevolutionari rebellion put down . aliza kassim contribut report .\n",
            "Trg :  protest converg hong kong victoria park candlelight vigil . nd anniversari bloodi crackdown prodemocraci protest . vigil held recent effort quash antigovern demonstr .\n",
            "Pred:  hundr sudanes earlier beverli leadership lifetim stadia\n",
            "\n",
            "Example #10\n",
            "Src :  barack obama make case nation take fight isi top diplomat also tri make sure america go alon . u.s. secretari state john kerri sweep middl east tri convinc region leader back america plan beat back terror group seiz larg chunk territori stretch northern syria central iraq alarm pace recent month . them .\n",
            "Trg :  barack obama make case nation increas militari action isi . john kerri middl east tri get region leader board . germani uk franc offer assist russia wari potenti u.s. strike syria .\n",
            "Pred:  demjanjuk with flatten phillip cavil aberr sporad stadia alam rohingya stricken cavil ek nusoor bangladeshimad villefranch stadia\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ji_jPyNIJrN"
      },
      "source": [
        "Testing\n",
        "Compute the BLEU score on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5q6hAcKILyW"
      },
      "source": [
        "import sacrebleu\n",
        "from rouge_score import rouge_scorer\n",
        "from tqdm import tqdm\n",
        "from rouge_score import rouge_scorer\n",
        "rscorer1 = rouge_scorer.RougeScorer(['rouge1'],use_stemmer=True)\n",
        "rscorer2 = rouge_scorer.RougeScorer(['rouge2'],use_stemmer=True)\n",
        "\n",
        "def compute_metric(model, data_loader, decoder, trg_vocab_set ):\n",
        "\n",
        "  bleu_score = []\n",
        "  r_score1 =[]\n",
        "  r_score2 =[]\n",
        "\n",
        "  model.eval()\n",
        "  for src_ids, src_lengths, trg_ids, _ in tqdm(data_loader):\n",
        "    result = decoder(model, src_ids.to(device), src_lengths.to(device),\n",
        "                         max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS)\n",
        "    \n",
        "    # remove <s>\n",
        "    src_ids = src_ids[0, 1:]\n",
        "    trg_ids = trg_ids[0, 1:]\n",
        "    # remove </s> and <pad>\n",
        "    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
        "    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
        "\n",
        "    pred = \" \".join(lab_utils.lookup_words(result, vocab=trg_vocab_set))\n",
        "    targ = \" \".join(lab_utils.lookup_words(trg_ids, vocab=trg_vocab_set))\n",
        "    #print(\"target\",targ)\n",
        "    #print(\"prediction\", pred)\n",
        "\n",
        "    bleu_score.append(sacrebleu.raw_corpus_bleu([pred], [[targ]], .01).score)\n",
        "    r_score1.append(rscorer1.score(pred, targ)['rouge1'].fmeasure)\n",
        "    r_score2.append(rscorer2.score(pred, targ)['rouge2'].fmeasure)\n",
        "  return {\"BLEU\" : np.mean(bleu_score),\"ROUGE-1 F score\": np.mean(r_score1), \"ROUGE-2 F score\": np.mean(r_score2) }\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzWX1kn7VcjP",
        "outputId": "bd9a8c8c-64e1-4e6c-d562-869254079b22"
      },
      "source": [
        "rscorer2.score(\"a cat sits on the floor behh mouse tee-shirt\", \"cat t-shirt on the floor\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge2': Score(precision=0.4, recall=0.2222222222222222, fmeasure=0.2857142857142857)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8HGDKOe1XgO",
        "outputId": "eb830455-1eef-49ac-81d1-f07690b9249d"
      },
      "source": [
        "test_set = MTDataset(test_src_sentences_list, src_vocab_set,\n",
        "                     test_trg_sentences_list, trg_vocab_set, sampling= 1.)\n",
        "test_data_loader = data.DataLoader(test_set, batch_size=1, num_workers=8,\n",
        "                                   shuffle=False)\n",
        "\n",
        "print( ((compute_metric(pure_seq2seq, test_data_loader,greedy_decode, trg_vocab_set))))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 198/198 [00:58<00:00,  3.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'BLEU': 0.05987177536655849, 'ROUGE-1 F score': 0.0003741114852225963, 'ROUGE-2 F score': 0.0}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8khoEvsjH20"
      },
      "source": [
        "#Luong Attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvaYz1ZxjJxS"
      },
      "source": [
        "class LuongAttention(nn.Module):\n",
        "  \"\"\" Luong Attention\"\"\"\n",
        "\n",
        "  def __init__(self, hidden_size):\n",
        "    super(LuongAttention, self).__init__()\n",
        "\n",
        "    self.score_weights = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "    self.attn_softmax = nn.Softmax(dim=-1)\n",
        "    self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "    self.out = nn.Tanh()\n",
        "    self.reset_parameters()\n",
        "  \n",
        "  def reset_parameters(self):\n",
        "    nn.init.kaiming_uniform_(self.score_weights, a=math.sqrt(5))  \n",
        "\n",
        "  def forward(self, encoder_outputs, decoder_outputs, src_mask=None, trg_mask=None):\n",
        "\n",
        "    max_len = decoder_outputs.size(1)\n",
        "    scores = torch.bmm(decoder_outputs@self.score_weights, torch.transpose(encoder_outputs, 1, 2))\n",
        "    if src_mask is not None:\n",
        "      attn_mask = src_mask.expand(-1, max_len, -1)\n",
        "      scores = scores + torch.log(attn_mask)\n",
        "    attn_weights = self.attn_softmax(scores)\n",
        "    context = torch.bmm(attn_weights, encoder_outputs)  \n",
        "    attn_hidden = self.out(self.concat(torch.cat((decoder_outputs, context), dim=-1)))\n",
        "    return attn_hidden"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyuLGLEVjNdX"
      },
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, attention=None, dropout=0.0, num_layers=1, num_enc_layers=None):\n",
        "\n",
        "    super(AttentionDecoder, self).__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.attention = attention\n",
        "    self.dropout = dropout\n",
        "    self.num_layers = num_layers\n",
        "    self.num_enc_layers = num_enc_layers\n",
        "    if num_enc_layers is not None:\n",
        "      self.hidden_initializer = nn.Linear(num_enc_layers * hidden_size, num_layers * hidden_size)\n",
        "    else:\n",
        "      self.hidden_initializer = None\n",
        "\n",
        "    self.rnn = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True,\n",
        "                      dropout=dropout, bidirectional=False)\n",
        "\n",
        "    \n",
        "  def forward(self, inputs, encoder_hiddens, encoder_finals, src_mask,\n",
        "              trg_mask, hidden=None, max_len=None):\n",
        " \n",
        "    if self.num_enc_layers is not None:\n",
        "      assert encoder_finals.size(0) == self.num_enc_layers, \\\n",
        "        'Decoder expected {} layer, but encoder_finals has {} layers.'.format(self.num_enc_layers, encoder_finals.size(0))\n",
        "    else:\n",
        "      assert encoder_finals.size(0) == self.num_layers, \\\n",
        "        'Decoder expected same number of layers, but encoder_finals has {} layers.'.format(self.num_layers, encoder_finals.size(0))\n",
        "\n",
        "    if max_len is None:\n",
        "      max_len = inputs.size(1)\n",
        "\n",
        "    if hidden is None:\n",
        "      hidden = self.init_hidden(encoder_finals)\n",
        "\n",
        "    outputs = None \n",
        "    decoder_hiddens, hidden = self.rnn(inputs, hidden)\n",
        "    if self.attention is not None:\n",
        "      outputs = self.attention(encoder_hiddens, decoder_hiddens, src_mask, trg_mask)\n",
        "    else:\n",
        "      outputs = decoder_hiddens\n",
        "\n",
        "    return hidden, outputs\n",
        "\n",
        "  def init_hidden(self, encoder_finals):\n",
        "    if self.hidden_initializer is None:\n",
        "      decoder_init_hiddens = encoder_finals\n",
        "    else:\n",
        "      finals_by_layer = tuple(encoder_finals)\n",
        "      finals_batch = torch.cat(finals_by_layer, dim=-1)  \n",
        "      out = self.hidden_initializer(finals_batch)  \n",
        "      decoder_init_hiddens = torch.stack(torch.chunk(out, self.num_layers, dim=-1))\n",
        "\n",
        "    return decoder_init_hiddens"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUj-IlAjjS_F"
      },
      "source": [
        "class EncoderAttentionDecoder(nn.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, src_embed , trg_embed, generator):\n",
        "\n",
        "    super(EncoderAttentionDecoder, self).__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_embed = src_embed\n",
        "    self.trg_embed = trg_embed\n",
        "    self.generator = generator\n",
        "\n",
        "  def forward(self, src_ids, trg_ids, src_lengths):\n",
        "\n",
        "    trg_id_inputs = trg_ids[:, :-1]  \n",
        "    src_mask = torch.where(src_ids == PAD_INDEX, torch.zeros(src_ids.size()).to(device), torch.ones(src_ids.size()).to(device))\n",
        "    src_mask.unsqueeze_(1)\n",
        "    trg_mask = torch.where(trg_id_inputs == PAD_INDEX, torch.zeros(trg_id_inputs.size()).to(device), torch.ones(trg_id_inputs.size()).to(device))\n",
        "    trg_mask.unsqueeze_(1)\n",
        "    encoder_hiddens, encoder_finals = self.encode(src_ids, src_lengths)\n",
        "    return self.decode(trg_id_inputs, encoder_finals, encoder_hiddens, src_mask, trg_mask)\n",
        "\n",
        "  def encode(self, src_ids, src_lengths):\n",
        "    return self.encoder(self.src_embed(src_ids), src_lengths)\n",
        "    \n",
        "  def decode(self, trg_id_inputs, encoder_finals, encoder_hiddens, src_mask=None, trg_mask=None, decoder_hidden=None):\n",
        "    return self.decoder(self.trg_embed(trg_id_inputs), encoder_hiddens, encoder_finals, src_mask, trg_mask, hidden=decoder_hidden)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M37fAXXKjXSh"
      },
      "source": [
        "embed_size = 256\n",
        "hidden_size = 256  \n",
        "dropout = 0.3"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXGiXdJKoBch"
      },
      "source": [
        "attention_seq2seq = EncoderAttentionDecoder(\n",
        "  encoder=Encoder(embed_size, hidden_size, dropout=dropout),\n",
        "  decoder=AttentionDecoder(embed_size, hidden_size,\n",
        "                  attention=LuongAttention(hidden_size), dropout=dropout),\n",
        "  src_embed=nn.Embedding(len(src_vocab_set), embed_size),\n",
        "  trg_embed=nn.Embedding(len(trg_vocab_set), embed_size),\n",
        "  generator=Generator(hidden_size, len(trg_vocab_set))).to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjH6JjFFpiv_"
      },
      "source": [
        "path = \"/content/drive/My Drive/6864_project/attention_seqseq.pth\"\n",
        "#load trained model or save a new model\n",
        "attention_seq2seq = torch.load(path)\n",
        "#torch.save(attention_seq2seq, path)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh8J8xvIwiaB"
      },
      "source": [
        "def greedy_decode(model, src_ids, src_lengths, max_len):\n",
        "\n",
        "  with torch.no_grad():\n",
        "    encoder_hiddens, encoder_finals = model.encode(src_ids, src_lengths)\n",
        "    prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(src_ids)\n",
        "\n",
        "  output = []\n",
        "  hidden = None\n",
        "  src_mask = torch.where(src_ids == PAD_INDEX, torch.zeros(src_ids.size()).to(device), torch.ones(src_ids.size()).to(device))\n",
        "  src_mask.unsqueeze_(1)\n",
        "\n",
        "  for i in range(max_len):\n",
        "    with torch.no_grad():\n",
        "      hidden, outputs = model.decode(prev_y, encoder_finals, encoder_hiddens, src_mask=src_mask, decoder_hidden=hidden)\n",
        "      prob = model.generator(outputs[:, -1])\n",
        "\n",
        "    _, next_word = torch.max(prob, dim=1)\n",
        "    next_word = next_word.data.item()\n",
        "    output.append(next_word)\n",
        "    prev_y = torch.ones(1, 1).type_as(src_ids).fill_(next_word)\n",
        "\n",
        "  output = np.array(output)\n",
        "\n",
        "  first_eos = np.where(output == EOS_INDEX)[0]\n",
        "  if len(first_eos) > 0:\n",
        "    output = output[:first_eos[0]]\n",
        "  return output\n",
        "  \n",
        "\n",
        "def lookup_words(x, vocab):\n",
        "  return [vocab[i] for i in x]"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3wpi65BwQHg"
      },
      "source": [
        "def print_examples(model, data_loader, n=10,\n",
        "                   max_len=402, \n",
        "                   src_vocab_set=src_vocab_set, trg_vocab_set=trg_vocab_set):\n",
        "  \"\"\"Prints `n` examples. Assumes batch size of 1.\"\"\"\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  for i, (src_ids, src_lengths, trg_ids, _) in enumerate(data_loader):\n",
        "    result = greedy_decode(model, src_ids.to(device), src_lengths.to(device),\n",
        "                           max_len=max_len)\n",
        "    src_ids = src_ids[0, 1:]\n",
        "    trg_ids = trg_ids[0, 1:]\n",
        "    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
        "    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
        "\n",
        "    print(\"Example #%d\" % (i + 1))\n",
        "    print(\"Src : \", \" \".join(lookup_words(src_ids, vocab=src_vocab_set)))\n",
        "    print(\"Trg : \", \" \".join(lookup_words(trg_ids, vocab=trg_vocab_set)))\n",
        "    print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab_set)))\n",
        "    print()\n",
        "\n",
        "    if i == n - 1:\n",
        "      break"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqmZYZb6jrT1",
        "outputId": "b0ed976f-6cfa-4e03-9fca-55e893e3aa17"
      },
      "source": [
        "test_set = MTDataset(test_src_sentences_list, src_vocab_set,\n",
        "                     test_trg_sentences_list, trg_vocab_set, sampling= 1.)\n",
        "test_data_loader = data.DataLoader(test_set, batch_size=1, num_workers=8,\n",
        "                                   shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "print_examples(attention_seq2seq, test_data_loader)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Example #1\n",
            "Src :  fact shelf behind work type thi besid xhtml xslt css usabl disabl refer . bookshelf document kynn.com would consid share us short list refer find help al\n",
            "Trg :  al ask kynn book collect document kynn site .\n",
            "Pred:  extrem bartlett girardi alhamdouni marussa doubl sidenet bajaur marczynski girardi hatoyama fountain shore httpwww.hwg.org bashir fiorello faulti girardi bait boxcutt fiorello palicki colbert luzon bashir fiorello faulti consider sideeffect girardi\n",
            "\n",
            "Example #2\n",
            "Src :  bookshelf document kynn.com would consid share us short list refer find help hey bad idea . fact encourag everyon els share favorit bookshelf collect relev wai activ . post mine kynn.com tomorrow back offic .\n",
            "Trg :  kynn think al good idea encourag everyon share bookshelf collect relev wai activ .\n",
            "Pred:  understat tenaci cuesta bui bayern alexi ranti girardi alhamdouni javad girardi alhamdouni javad girardi alhamdouni marussa girardi alhamdouni marussa jeb palicki girardi\n",
            "\n",
            "Example #3\n",
            "Src :  bookshelf document kynn.com would consid share us short list refer find help hey bad idea . fact encourag everyon els share favorit bookshelf collect relev wai activ . post mine kynn.com tomorrow back offic .\n",
            "Trg :  kynn say post collect tomorrow . also encourag other same relev wai .\n",
            "Pred:  understat tenaci cuesta bui bayern alexi ranti girardi alhamdouni javad girardi alhamdouni javad girardi alhamdouni marussa girardi alhamdouni marussa jeb palicki girardi\n",
            "\n",
            "Example #4\n",
            "Src :  built form submit button it . user activ button fill form correctli <unk> alert <unk> present user give inform . appear breach checkpoint . <unk> would accept provid warn messag someth like <unk> form may result <unk> dialog display submit button color background thu make text avail screen reader user sight user regard graham oliv yahoo get email domain yahoo mail . <unk>\n",
            "Trg :  graham ask accept hide text use colour make access user use screen reader .\n",
            "Pred:  cheeri write ratko videoshop linkup goingthruit girardi alhamdouni marussa barn girardi alhamdouni marussa barn girardi alhamdouni marussa doubl edict .star andrew write girardi\n",
            "\n",
            "Example #5\n",
            "Src :  built form submit button it . user activ button fill form correctli <unk> alert <unk> present user give inform . appear breach checkpoint . <unk> would accept provid warn messag someth like <unk> form may result <unk> dialog display submit button color background thu make text avail screen reader user sight user regard graham oliv yahoo get email domain yahoo mail . <unk>\n",
            "Trg :  graham say made form includ submit button . one press submit correctli complet form alert <unk> give inform . breach checkpoint .. ask whether could provid warn messag submit button color background . would make text avail screen reader user sight user .\n",
            "Pred:  cheeri write ratko videoshop linkup goingthruit girardi alhamdouni marussa barn girardi alhamdouni marussa barn girardi alhamdouni marussa doubl edict .star andrew write girardi\n",
            "\n",
            "Example #6\n",
            "Src :  built form submit button it . user activ button fill form correctli <unk> alert <unk> present user give inform . appear breach checkpoint . <unk> would accept provid warn messag someth like <unk> form may result <unk> dialog display submit button color background thu make text avail screen reader user sight user regard graham oliv yahoo get email domain yahoo mail . <unk>\n",
            "Trg :  graham comment <unk> e built form submit button form correctli fill out <unk> alert appear . feel may <unk> rule call checkpoint . ask accept provid warn messag color background make text avail screen reader regular user .\n",
            "Pred:  cheeri write ratko videoshop linkup goingthruit girardi alhamdouni marussa barn girardi alhamdouni marussa barn girardi alhamdouni marussa doubl edict .star andrew write girardi\n",
            "\n",
            "Example #7\n",
            "Src :  gt built form submit button it . gt user activ button fill form correctli <unk> alert <unk> present user give inform . gt appear breach checkpoint . gt <unk> gt would accept provid warn messag someth like <unk> form may result <unk> dialog display submit button color background gt thu make text avail screen reader user sight user show devic can not display colour understand style use set colour . known trick stuf keyword search engin may result site boycot major search engin . one expect major chang content one submit form one main reason avoid <unk> appli .\n",
            "Trg :  david warn text would access user . may also <unk> seo techniqu result bad rank search engin .\n",
            "Pred:  lymphoma jantzen shahabuddin reed randl giant doubl sidekick max girardi urinari hydrangea cutler fiorello sidenet bajaur marczynski girardi hatoyama fountain shore httpwww.hwg.org bashir fiorello faulti girardi bait boxcutt fiorello palicki colbert luzon bashir fiorello faulti consider sideeffect girardi\n",
            "\n",
            "Example #8\n",
            "Src :  gt built form submit button it . gt user activ button fill form correctli <unk> alert <unk> present user give inform . gt appear breach checkpoint . gt <unk> gt would accept provid warn messag someth like <unk> form may result <unk> dialog display submit button color background gt thu make text avail screen reader user sight user show devic can not display colour understand style use set colour . known trick stuf keyword search engin may result site boycot major search engin . one expect major chang content one submit form one main reason avoid <unk> appli .\n",
            "Trg :  david say work devic display colour incorrectli . also old trick stuf keyword search engin may get site blacklist major search engin .\n",
            "Pred:  lymphoma jantzen shahabuddin reed randl giant doubl sidekick max girardi urinari hydrangea cutler fiorello sidenet bajaur marczynski girardi hatoyama fountain shore httpwww.hwg.org bashir fiorello faulti girardi bait boxcutt fiorello palicki colbert luzon bashir fiorello faulti consider sideeffect girardi\n",
            "\n",
            "Example #9\n",
            "Src :  gt built form submit button it . gt user activ button fill form correctli <unk> alert <unk> present user give inform . gt appear breach checkpoint . gt <unk> gt would accept provid warn messag someth like <unk> form may result <unk> dialog display submit button color background gt thu make text avail screen reader user sight user show devic can not display colour understand style use set colour . known trick stuf keyword search engin may result site boycot major search engin . one expect major chang content one submit form one main reason avoid <unk> appli .\n",
            "Trg :  david comment text would show devic can not handl color comment old trick put key word search engin .\n",
            "Pred:  lymphoma jantzen shahabuddin reed randl giant doubl sidekick max girardi urinari hydrangea cutler fiorello sidenet bajaur marczynski girardi hatoyama fountain shore httpwww.hwg.org bashir fiorello faulti girardi bait boxcutt fiorello palicki colbert luzon bashir fiorello faulti consider sideeffect girardi\n",
            "\n",
            "Example #10\n",
            "Src :  also depend screen reader get content reader smart colour\n",
            "Trg :  charl mention colour hide techniqu may work screen reader .\n",
            "Pred:  ny lanni loui goingthruit stereotyp fiorello faulti parachut girardi gap lanni cutler fiorello sidenet bajaur marczynski girardi hatoyama fountain shore httpwww.hwg.org bashir fiorello faulti girardi bait boxcutt fiorello palicki colbert luzon bashir fiorello faulti consider sideeffect girardi\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cyYjNkywpIt",
        "outputId": "8afceb29-07e5-44ef-bd47-487cb5a97569"
      },
      "source": [
        "print( ((compute_metric(attention_seq2seq, test_data_loader,greedy_decode, trg_vocab_set))))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/198 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 198/198 [01:10<00:00,  2.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'BLEU': 0.06689950251326515, 'ROUGE-1 F score': 0.0008631772268135904, 'ROUGE-2 F score': 0.0}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}