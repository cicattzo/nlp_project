{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP Fine Tuned Summarization Model Denis GPT2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d60fa3448c2f408fb33e1d54b18997bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f897651ab8d94ed2b58912333572b716",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b48ddb3e35984134914965a3357bfe54",
              "IPY_MODEL_dda582b86531495eaaeabc2b7b442485"
            ]
          }
        },
        "f897651ab8d94ed2b58912333572b716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b48ddb3e35984134914965a3357bfe54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_55cfb8c4112b4df5aa8de498cd121e32",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4815a3dae5844416ac0336173c6a459b"
          }
        },
        "dda582b86531495eaaeabc2b7b442485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c61697ce3828448aa0ea7e40d0194d40",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:01&lt;00:00, 573B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5a786e73ba84033b8748a1aa6931c3d"
          }
        },
        "55cfb8c4112b4df5aa8de498cd121e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4815a3dae5844416ac0336173c6a459b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c61697ce3828448aa0ea7e40d0194d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5a786e73ba84033b8748a1aa6931c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7877ab3f4ea45c589a5f19fd96e62ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a04bfa3a6ca040d990c9feb92bbf35b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_08af6d45c4474e33a099f6357d125515",
              "IPY_MODEL_b561a24cd980408d95edc461c65fb03b"
            ]
          }
        },
        "a04bfa3a6ca040d990c9feb92bbf35b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08af6d45c4474e33a099f6357d125515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cd03535295d7466c974f59cbd045b52e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce7a804dd52842b58aed07a1de18340e"
          }
        },
        "b561a24cd980408d95edc461c65fb03b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce6f71be2b054af7a38ad7ace1e9e34d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:07&lt;00:00, 147kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9c1320c40414639bfb084b7308b92ba"
          }
        },
        "cd03535295d7466c974f59cbd045b52e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce7a804dd52842b58aed07a1de18340e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce6f71be2b054af7a38ad7ace1e9e34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9c1320c40414639bfb084b7308b92ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a07d0a3d5bdb4f17be9d06510a2fdb65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_478161b797fa44ae8ad61c1f7ad1102b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_623969362d17422dbf04181f56ca767d",
              "IPY_MODEL_1723731135a74b36aad4b2eb1bd2b427"
            ]
          }
        },
        "478161b797fa44ae8ad61c1f7ad1102b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "623969362d17422dbf04181f56ca767d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_be2809ab22ae4c6d9129ec7fbc41d83b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65ce1ef5d73348ffaa2c9d42a72cedf4"
          }
        },
        "1723731135a74b36aad4b2eb1bd2b427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_645916d9b40e4251a44857378d62f11d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:04&lt;00:00, 93.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce7cd17ec3974c5ea55686ffaf0fb261"
          }
        },
        "be2809ab22ae4c6d9129ec7fbc41d83b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65ce1ef5d73348ffaa2c9d42a72cedf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "645916d9b40e4251a44857378d62f11d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce7cd17ec3974c5ea55686ffaf0fb261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91640d382d344dada90ba0f23945f259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8768b46b500c48b597608ae4e3462bdd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65fe21aea0454bcdb6c6c138ec8f169c",
              "IPY_MODEL_d0aa3fdc698e4f76803172b140313b44"
            ]
          }
        },
        "8768b46b500c48b597608ae4e3462bdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65fe21aea0454bcdb6c6c138ec8f169c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b4480061d983404c87ba820db6c5fddd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355256,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355256,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d51a98ed20cd48c1873e3540663dc839"
          }
        },
        "d0aa3fdc698e4f76803172b140313b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1f425c5f9ab846c9be41449095e3b604",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:02&lt;00:00, 470kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2bceca1affcf43d49e57395e15122d1a"
          }
        },
        "b4480061d983404c87ba820db6c5fddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d51a98ed20cd48c1873e3540663dc839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f425c5f9ab846c9be41449095e3b604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2bceca1affcf43d49e57395e15122d1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69c9856c4e9c44b39fdc4c8cacc85bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6a816f59f42e4315a771daecd58d6dc8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a6bf8734973c4bff84b23eea014150cd",
              "IPY_MODEL_9d120252c74e443082046478f6a6d7f0"
            ]
          }
        },
        "6a816f59f42e4315a771daecd58d6dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6bf8734973c4bff84b23eea014150cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e0f63203ac98440da330a79a1a1282f9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548118077,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548118077,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93a149ce017f41d4a81b0cc5f5d50062"
          }
        },
        "9d120252c74e443082046478f6a6d7f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b90f9a06ec644aab8f944f03292ca7a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:13&lt;00:00, 39.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a0beab319ad424e953f2bc45abef54f"
          }
        },
        "e0f63203ac98440da330a79a1a1282f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93a149ce017f41d4a81b0cc5f5d50062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b90f9a06ec644aab8f944f03292ca7a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a0beab319ad424e953f2bc45abef54f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cicattzo/nlp_project/blob/main/NLP_Fine_Tuned_Summarization_Model_Denis_GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1sS8CzC9P_9",
        "outputId": "30cb10e4-46d6-47b4-ac5b-d5c57c553f1e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4hJGSvaDL6N"
      },
      "source": [
        "'''Define the model you want to run here:'''\n",
        "\n",
        "'''Wanted data sets the dataset to train on. The options are:\n",
        "cnn - full cnn dataset from online\n",
        "cnn_sample - cnn sample dataset from the dropbox\n",
        "bc3 - bc3 dataset from the dropbox\n",
        "merged_data - merged dataset from the dropbox'''\n",
        "wanted_data = 'merged_data'\n",
        "\n",
        "'''pretrained_model_name determines the pretrained model to load prior to training. The options are:\n",
        "bert - trains a bert-base-uncased to bert-base-uncased encoder decoder model\n",
        "gpt2 - trains a gp2 encoder decoder model\n",
        "pretrained_summarizer - pretrained summarization model on financial reports'''\n",
        "pretrained_model_name = 'gpt2'\n",
        "\n",
        "'''Model type determines the architecture of the model to train on. The options are:\n",
        "original - fine tuned model with only a single linear layer\n",
        "bottleneck - bottleneck fine tuning with a linear layer scaling it down, dropout, then scaling it back up'''\n",
        "model_type = 'bottleneck'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__HCs3MArp2L",
        "outputId": "bff5cece-eec7-4c12-a69f-bd99fd91abb6"
      },
      "source": [
        "%%bash\n",
        "pip -q install torch\n",
        "pip -q install transformers\n",
        "# pip -q install datasets\n",
        "pip -q install tqdm\n",
        "pip -q install rouge_score\n",
        "pip -q install sacrebleu\n",
        "pip install datasets==1.0.2\n",
        "pip install sumy\n",
        "# pip install transformers==4.0.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets==1.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/83/7e/8d9e2fd30e3819e6042927d379f3668a0b49fe38b92d5639194808a1d877/datasets-1.0.2-py3-none-any.whl (1.8MB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (1.1.5)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (1.19.5)\n",
            "Collecting xxhash\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (0.3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (4.41.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.0.2) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.0.2) (2.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.2) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.2) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.0.2) (1.15.0)\n",
            "Installing collected packages: xxhash, datasets\n",
            "Successfully installed datasets-1.0.2 xxhash-2.0.2\n",
            "Collecting sumy\n",
            "  Downloading https://files.pythonhosted.org/packages/61/20/8abf92617ec80a2ebaec8dc1646a790fc9656a4a4377ddb9f0cc90bc9326/sumy-0.8.1-py2.py3-none-any.whl (83kB)\n",
            "Collecting breadability>=0.1.20\n",
            "  Downloading https://files.pythonhosted.org/packages/ad/2d/bb6c9b381e6b6a432aa2ffa8f4afdb2204f1ff97cfcc0766a5b7683fec43/breadability-0.1.20.tar.gz\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from sumy) (2.23.0)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from sumy) (3.2.5)\n",
            "Collecting pycountry>=18.2.23\n",
            "  Downloading https://files.pythonhosted.org/packages/76/73/6f1a412f14f68c273feea29a6ea9b9f1e268177d32e0e69ad6790d306312/pycountry-20.7.3.tar.gz (10.1MB)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from breadability>=0.1.20->sumy) (3.0.4)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.7/dist-packages (from breadability>=0.1.20->sumy) (4.2.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->sumy) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.0.2->sumy) (1.15.0)\n",
            "Building wheels for collected packages: breadability, pycountry\n",
            "  Building wheel for breadability (setup.py): started\n",
            "  Building wheel for breadability (setup.py): finished with status 'done'\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21680 sha256=786f3cbeb5821d0abc364f3665bc0af17a5f63179471abde5710dbdc6d5a3995\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/4d/a1/510b12c5e65e0b2b3ce539b2af66da0fc57571e528924f4a52\n",
            "  Building wheel for pycountry (setup.py): started\n",
            "  Building wheel for pycountry (setup.py): finished with status 'done'\n",
            "  Created wheel for pycountry: filename=pycountry-20.7.3-py2.py3-none-any.whl size=10746863 sha256=1e750528ec57c30862f9937909e33a082f64b79ac27e13e29517a77ff3d352d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/4e/a6/be297e6b83567e537bed9df4a93f8590ec01c1acfbcd405348\n",
            "Successfully built breadability pycountry\n",
            "Installing collected packages: breadability, pycountry, sumy\n",
            "Successfully installed breadability-0.1.20 pycountry-20.7.3 sumy-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yY7mMfIVh9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a0049e0-23a3-4333-aad0-84cb73e94460"
      },
      "source": [
        "%%bash\n",
        "mkdir \"/content/gdrive/MyDrive/6864_project/\"\n",
        "cd \"/content/gdrive/MyDrive/6864_project/\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/gdrive/MyDrive/6864_project/’: File exists\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h6gz7k09y2W"
      },
      "source": [
        "MODEL_FOLDER = \"/content/gdrive/MyDrive/6864_project/\"\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import datasets\n",
        "import transformers\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer\n",
        "from sumy.nlp.stemmers import Stemmer\n",
        "from sumy.utils import get_stop_words\n",
        "from IPython.display import display"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDaBn89-ruff"
      },
      "source": [
        "#decide which dataset we want to train on \n",
        "if wanted_data == 'cnn':\n",
        "  train_data = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:5%]\")\n",
        "  train_data = [x for x in train_data]\n",
        "  full_text_key = 'article'\n",
        "  label_key = 'highlights'\n",
        "elif wanted_data == 'bc3':\n",
        "  import nltk\n",
        "  nltk.download('punkt')\n",
        "\n",
        "  #setting up to preprocess bc3 data\n",
        "  LANGUAGE = \"english\"\n",
        "  SENTENCES_COUNT = 10\n",
        "  tokenizer = Tokenizer(LANGUAGE)\n",
        "  stemmer = Stemmer(LANGUAGE)\n",
        "  \n",
        "  # change this line to any other summarizer\n",
        "  summarizer = TextRankSummarizer(stemmer)\n",
        "  summarizer.stop_words = get_stop_words(LANGUAGE)\n",
        "\n",
        "  #reading in and processing data\n",
        "  bc3_df = pd.read_csv(MODEL_FOLDER+\"bc3_processed.csv\")\n",
        "  txt = bc3_df.iloc[0]['body']\n",
        "  summary = bc3_df.iloc[0]['summary']\n",
        "  parser = PlaintextParser.from_string(txt, tokenizer)\n",
        "  # keeping the subject and body separate, but they can be merged\n",
        "  bc3_df['unique_key'] = bc3_df['listno'] + \"-\" + bc3_df['email_num'].astype(str)\n",
        "  # train_data = bc3_df.groupby('unique_key').agg({'subject':lambda x: x.iloc[0], 'body':lambda x: x.iloc[0], 'summary':lambda x: x.to_list()}).to_dict('records')\n",
        "  train_data = bc3_df.agg({'subject':lambda x: x.iloc[0], 'body':lambda x: x.iloc[0], 'summary':lambda x: x}).to_dict('records')\n",
        "\n",
        "  test_data_pd = pd.read_csv(MODEL_FOLDER+\"bc3_test.csv\")\n",
        "  test_data = test_data_pd.to_dict('records')\n",
        "  test_data = [x for x in test_data]\n",
        "\n",
        "  full_text_key = 'body'\n",
        "  label_key = 'summary'\n",
        "elif wanted_data == 'cnn_sample':\n",
        "  train_data_pd = pd.read_csv(MODEL_FOLDER+\"cnn_train_data_5.csv\")\n",
        "  test_data_pd = pd.read_csv(MODEL_FOLDER+\"bc3_test.csv\")\n",
        "\n",
        "  train_data = train_data_pd.to_dict('records')\n",
        "  train_data = [x for x in train_data]\n",
        "\n",
        "  test_data = test_data_pd.to_dict('records')\n",
        "  test_data = [x for x in test_data]\n",
        "\n",
        "  full_text_key = 'article'\n",
        "  label_key = 'highlights'\n",
        "\n",
        "elif wanted_data == 'merged_data':\n",
        "  train_data_pd = pd.read_csv(MODEL_FOLDER+\"train_combined.csv\")\n",
        "  test_data_pd = pd.read_csv(MODEL_FOLDER+\"bc3_test.csv\")\n",
        "\n",
        "  train_data = train_data_pd.to_dict('records')\n",
        "  train_data = [x for x in train_data]\n",
        "\n",
        "  test_data = test_data_pd.to_dict('records')\n",
        "  test_data = [x for x in test_data]\n",
        "\n",
        "  full_text_key = 'article'\n",
        "  label_key = 'highlights'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jT5ANJyBWDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbda0a62-7f30-4209-971d-66a331be9d48"
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'article': 'It\\'s official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It\\'s a step that is set to turn an international crisis into a fierce domestic political battle. There are key questions looming over the debate: What did U.N. weapons inspectors find in Syria? What happens if Congress votes no? And how will the Syrian government react? In a televised address from the White House Rose Garden earlier Saturday, the president said he would take his case to Congress, not because he has to -- but because he wants to. \"While I believe I have the authority to carry out this military action without specific congressional authorization, I know that the country will be stronger if we take this course, and our actions will be even more effective,\" he said. \"We should have this debate, because the issues are too big for business as usual.\" Obama said top congressional leaders had agreed to schedule a debate when the body returns to Washington on September 9. The Senate Foreign Relations Committee will hold a hearing over the matter on Tuesday, Sen. Robert Menendez said. Transcript: Read Obama\\'s full remarks . Syrian crisis: Latest developments . U.N. inspectors leave Syria . Obama\\'s remarks came shortly after U.N. inspectors left Syria, carrying evidence that will determine whether chemical weapons were used in an attack early last week in a Damascus suburb. \"The aim of the game here, the mandate, is very clear -- and that is to ascertain whether chemical weapons were used -- and not by whom,\" U.N. spokesman Martin Nesirky told reporters on Saturday. But who used the weapons in the reported toxic gas attack in a Damascus suburb on August 21 has been a key point of global debate over the Syrian crisis. Top U.S. officials have said there\\'s no doubt that the Syrian government was behind it, while Syrian officials have denied responsibility and blamed jihadists fighting with the rebels. British and U.S. intelligence reports say the attack involved chemical weapons, but U.N. officials have stressed the importance of waiting for an official report from inspectors. The inspectors will share their findings with U.N. Secretary-General Ban Ki-moon Ban, who has said he wants to wait until the U.N. team\\'s final report is completed before presenting it to the U.N. Security Council. The Organization for the Prohibition of Chemical Weapons, which nine of the inspectors belong to, said Saturday that it could take up to three weeks to analyze the evidence they collected. \"It needs time to be able to analyze the information and the samples,\" Nesirky said. He noted that Ban has repeatedly said there is no alternative to a political solution to the crisis in Syria, and that \"a military solution is not an option.\" Bergen:  Syria is a problem from hell for the U.S. Obama: \\'This menace must be confronted\\' Obama\\'s senior advisers have debated the next steps to take, and the president\\'s comments Saturday came amid mounting political pressure over the situation in Syria. Some U.S. lawmakers have called for immediate action while others warn of stepping into what could become a quagmire. Some global leaders have expressed support, but the British Parliament\\'s vote against military action earlier this week was a blow to Obama\\'s hopes of getting strong backing from key NATO allies. On Saturday, Obama proposed what he said would be a limited military action against Syrian President Bashar al-Assad. Any military attack would not be open-ended or include U.S. ground forces, he said. Syria\\'s alleged use of chemical weapons earlier this month \"is an assault on human dignity,\" the president said. A failure to respond with force, Obama argued,  \"could lead to escalating use of chemical weapons or their proliferation to terrorist groups who would do our people harm. In a world with many dangers, this menace must be confronted.\" Syria missile strike: What would happen next? Map: U.S. and allied assets around Syria . Obama decision came Friday night . On Friday night, the president made a last-minute decision to consult lawmakers. What will happen if they vote no? It\\'s unclear. A senior administration official told CNN that Obama has the authority to act without Congress -- even if Congress rejects his request for authorization to use force. Obama on Saturday continued to shore up support for a strike on the al-Assad government. He spoke by phone with French President Francois Hollande before his Rose Garden speech. \"The two leaders agreed that the international community must deliver a resolute message to the Assad regime -- and others who would consider using chemical weapons -- that these crimes are unacceptable and those who violate this international norm will be held accountable by the world,\" the White House said. Meanwhile, as uncertainty loomed over how Congress would weigh in, U.S. military officials said they remained at the ready. 5 key assertions: U.S. intelligence report on Syria . Syria: Who wants what after chemical weapons horror . Reactions mixed to Obama\\'s speech . A spokesman for the Syrian National Coalition said that the opposition group was disappointed by Obama\\'s announcement. \"Our fear now is that the lack of action could embolden the regime and they repeat his attacks in a more serious way,\" said spokesman Louay Safi. \"So we are quite concerned.\" Some members of Congress applauded Obama\\'s decision. House Speaker John Boehner, Majority Leader Eric Cantor, Majority Whip Kevin McCarthy and Conference Chair Cathy McMorris Rodgers issued a statement Saturday praising the president. \"Under the Constitution, the responsibility to declare war lies with Congress,\" the Republican lawmakers said. \"We are glad the president is seeking authorization for any military action in Syria in response to serious, substantive questions being raised.\" More than 160 legislators, including 63 of Obama\\'s fellow Democrats, had signed letters calling for either a vote or at least a \"full debate\" before any U.S. action. British Prime Minister David Cameron, whose own attempt to get lawmakers in his country to support military action in Syria failed earlier this week, responded to Obama\\'s speech in a Twitter post Saturday. \"I understand and support Barack Obama\\'s position on Syria,\" Cameron said. An influential lawmaker in Russia -- which has stood by Syria and criticized the United States -- had his own theory. \"The main reason Obama is turning to the Congress:  the military operation did not get enough support either in the world, among allies of the US or in the United States itself,\" Alexei Pushkov, chairman of the international-affairs committee of the Russian State Duma, said in a Twitter post. In the United States, scattered groups of anti-war protesters around the country took to the streets Saturday. \"Like many other Americans...we\\'re just tired of the United States getting involved and invading and bombing other countries,\" said Robin Rosecrans, who was among hundreds at a Los Angeles demonstration. What do Syria\\'s neighbors think? Why Russia, China, Iran stand by Assad . Syria\\'s government unfazed . After Obama\\'s speech, a military and political analyst on Syrian state TV said Obama is \"embarrassed\" that Russia opposes military action against Syria, is \"crying for help\" for someone to come to his rescue and is facing two defeats -- on the political and military levels. Syria\\'s prime minister appeared unfazed by the saber-rattling. \"The Syrian Army\\'s status is on maximum readiness and fingers are on the trigger to confront all challenges,\" Wael Nader al-Halqi said during a meeting with a delegation of Syrian expatriates from Italy, according to a banner on Syria State TV that was broadcast prior to Obama\\'s address. An anchor on Syrian state television said Obama \"appeared to be preparing for an aggression on Syria based on repeated lies.\" A top Syrian diplomat told the state television network that Obama was facing pressure to take military action from Israel, Turkey, some Arabs and right-wing extremists in the United States. \"I think he has done well by doing what Cameron did in terms of taking the issue to Parliament,\" said Bashar Jaafari, Syria\\'s ambassador to the United Nations. Both Obama and Cameron, he said, \"climbed to the top of the tree and don\\'t know how to get down.\" The Syrian government has denied that it used chemical weapons in the August 21 attack, saying that jihadists fighting with the rebels used them in an effort to turn global sentiments against it. British intelligence had put the number of people killed in the attack at more than 350. On Saturday, Obama said \"all told, well over 1,000 people were murdered.\" U.S. Secretary of State John Kerry on Friday cited a death toll of 1,429, more than 400 of them children. No explanation was offered for the discrepancy. Iran: U.S. military action in Syria would spark \\'disaster\\' Opinion: Why strikes in Syria are a bad idea .', 'highlights': 'Syrian official: Obama climbed to the top of the tree, \"doesn\\'t know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .', 'id': '0001d1afc246a7964130f43ae940af6bc6c57f01'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xreA7ZYSrwIa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "d60fa3448c2f408fb33e1d54b18997bb",
            "f897651ab8d94ed2b58912333572b716",
            "b48ddb3e35984134914965a3357bfe54",
            "dda582b86531495eaaeabc2b7b442485",
            "55cfb8c4112b4df5aa8de498cd121e32",
            "4815a3dae5844416ac0336173c6a459b",
            "c61697ce3828448aa0ea7e40d0194d40",
            "d5a786e73ba84033b8748a1aa6931c3d",
            "a7877ab3f4ea45c589a5f19fd96e62ea",
            "a04bfa3a6ca040d990c9feb92bbf35b9",
            "08af6d45c4474e33a099f6357d125515",
            "b561a24cd980408d95edc461c65fb03b",
            "cd03535295d7466c974f59cbd045b52e",
            "ce7a804dd52842b58aed07a1de18340e",
            "ce6f71be2b054af7a38ad7ace1e9e34d",
            "f9c1320c40414639bfb084b7308b92ba",
            "a07d0a3d5bdb4f17be9d06510a2fdb65",
            "478161b797fa44ae8ad61c1f7ad1102b",
            "623969362d17422dbf04181f56ca767d",
            "1723731135a74b36aad4b2eb1bd2b427",
            "be2809ab22ae4c6d9129ec7fbc41d83b",
            "65ce1ef5d73348ffaa2c9d42a72cedf4",
            "645916d9b40e4251a44857378d62f11d",
            "ce7cd17ec3974c5ea55686ffaf0fb261",
            "91640d382d344dada90ba0f23945f259",
            "8768b46b500c48b597608ae4e3462bdd",
            "65fe21aea0454bcdb6c6c138ec8f169c",
            "d0aa3fdc698e4f76803172b140313b44",
            "b4480061d983404c87ba820db6c5fddd",
            "d51a98ed20cd48c1873e3540663dc839",
            "1f425c5f9ab846c9be41449095e3b604",
            "2bceca1affcf43d49e57395e15122d1a"
          ]
        },
        "outputId": "df67937f-0847-44d2-b041-1d5f1197cd6d"
      },
      "source": [
        "#intializing the tokenizer and choosing the pretrained model\n",
        "from transformers import PegasusTokenizer, PegasusForConditionalGeneration, TFPegasusForConditionalGeneration\n",
        "\n",
        "if pretrained_model_name == 'bert':\n",
        "  tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "elif pretrained_model_name == 'gpt2':\n",
        "  tokenizer = transformers.AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "  # tokenizer.add_special_tokens({'pad_token': -100})\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "elif pretrained_model_name =='pretrained_summarizer':\n",
        "  model_name = \"human-centered-summarization/financial-summarization-pegasus\"\n",
        "  tokenizer = PegasusTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d60fa3448c2f408fb33e1d54b18997bb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7877ab3f4ea45c589a5f19fd96e62ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a07d0a3d5bdb4f17be9d06510a2fdb65",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91640d382d344dada90ba0f23945f259",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPGSwKNcr6g7"
      },
      "source": [
        "'''Defining our text summarization model as a class'''\n",
        "import torch.nn as nn\n",
        "device = 'cuda'\n",
        "encoder_max_length = 512\n",
        "decoder_max_length = 128\n",
        "\n",
        "class ModelOutputs:\n",
        "    def __init__(self, logits=None, loss=None):\n",
        "        self.logits = logits\n",
        "        self.loss = loss\n",
        "\n",
        "if model_type == 'original':\n",
        "  class TextSummarizationModel(nn.Module):\n",
        "\n",
        "      def __init__(self, lm=None):\n",
        "          '''\n",
        "          lm:         a pretrained transformer language model\n",
        "          dropout:    dropoutrate for the dropout layer\n",
        "          '''\n",
        "          super(TextSummarizationModel, self).__init__()\n",
        "          self.pretrained_model = lm\n",
        "          self.linear_layer = nn.Linear(lm.config.encoder.vocab_size, lm.config.encoder.vocab_size)\n",
        "      \n",
        "      def forward(self, input_ids=None, labels=None): #dont think I need anything besides input ids\n",
        "\n",
        "          outputs = self.pretrained_model(input_ids=input_ids, decoder_input_ids = labels)\n",
        "          logits = outputs.logits\n",
        "          new_logits = self.linear_layer(logits)  \n",
        "          final_logits = logits.permute(0,2,1)\n",
        "          \n",
        "          if labels is not None:\n",
        "            loss_fct = nn.NLLLoss(reduction=\"mean\").to(device)\n",
        "\n",
        "            loss = loss_fct(final_logits, labels)\n",
        "          else:\n",
        "            loss = 0\n",
        "          \n",
        "          return ModelOutputs(\n",
        "              logits=new_logits,\n",
        "              loss=loss)\n",
        "elif model_type == 'bottleneck':\n",
        "  class TextSummarizationModel(nn.Module):\n",
        "\n",
        "      def __init__(self, lm=None):\n",
        "          '''\n",
        "          lm:         a pretrained transformer language model\n",
        "          dropout:    dropoutrate for the dropout layer\n",
        "          '''\n",
        "          super(TextSummarizationModel, self).__init__()\n",
        "          self.pretrained_model = lm\n",
        "          self.bottleneck = nn.Linear(lm.config.encoder.vocab_size, int(lm.config.encoder.vocab_size * 0.5))\n",
        "          self.dropout_layer = nn.Dropout(p=0.2)\n",
        "          self.upscale = nn.Linear(int(lm.config.encoder.vocab_size * 0.5), lm.config.encoder.vocab_size)\n",
        "      \n",
        "      def forward(self, input_ids=None, labels=None): #dont think I need anything besides input ids\n",
        "\n",
        "          outputs = self.pretrained_model(input_ids=input_ids, decoder_input_ids = labels)\n",
        "          logits = outputs.logits\n",
        "          new_logits = self.bottleneck(logits)  \n",
        "          new_logits = self.dropout_layer(new_logits)\n",
        "          new_logits = self.upscale(new_logits)\n",
        "          final_logits = logits.permute(0,2,1)\n",
        "          \n",
        "          if labels is not None:\n",
        "            loss_fct = nn.NLLLoss(reduction=\"mean\").to(device)\n",
        "\n",
        "            loss = loss_fct(final_logits, labels)\n",
        "          else:\n",
        "            loss = 0\n",
        "          \n",
        "          return ModelOutputs(\n",
        "              logits=new_logits,\n",
        "              loss=loss)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "69c9856c4e9c44b39fdc4c8cacc85bd8",
            "6a816f59f42e4315a771daecd58d6dc8",
            "a6bf8734973c4bff84b23eea014150cd",
            "9d120252c74e443082046478f6a6d7f0",
            "e0f63203ac98440da330a79a1a1282f9",
            "93a149ce017f41d4a81b0cc5f5d50062",
            "b90f9a06ec644aab8f944f03292ca7a0",
            "6a0beab319ad424e953f2bc45abef54f"
          ]
        },
        "id": "4bHn3MS7MXa0",
        "outputId": "1f3876ce-ef00-4065-fa44-0631e7200243"
      },
      "source": [
        "'''intializing our BERT pretrained encoder decoder model and using GPU'''\n",
        "\n",
        "# from transformers import BertConfig, EncoderDecoderConfig, EncoderDecoderModel\n",
        "from transformers import EncoderDecoderModel\n",
        "\n",
        "if pretrained_model_name == 'bert':\n",
        "  enc_dec_pretrained = EncoderDecoderModel.from_encoder_decoder_pretrained('bert-base-uncased', 'bert-base-uncased')\n",
        "elif pretrained_model_name == 'gpt2':\n",
        "  enc_dec_pretrained = EncoderDecoderModel.from_encoder_decoder_pretrained('gpt2', 'gpt2')\n",
        "elif pretrained_model_name == 'pretrained_summarizer':\n",
        "  model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "#defining it into our class\n",
        "model = TextSummarizationModel(enc_dec_pretrained)\n",
        "model = model.to(device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69c9856c4e9c44b39fdc4c8cacc85bd8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.11.attn.masked_bias', 'h.6.attn.masked_bias', 'h.3.attn.masked_bias', 'h.2.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.1.attn.masked_bias', 'h.9.attn.masked_bias', 'h.5.attn.masked_bias', 'h.4.attn.masked_bias', 'h.10.attn.masked_bias', 'h.0.attn.masked_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.10.ln_cross_attn.weight', 'h.11.crossattention.bias', 'h.9.crossattention.q_attn.weight', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.masked_bias', 'h.11.crossattention.c_proj.weight', 'h.10.crossattention.bias', 'h.1.crossattention.bias', 'h.3.crossattention.c_proj.bias', 'h.11.crossattention.masked_bias', 'h.10.crossattention.q_attn.weight', 'h.5.crossattention.c_attn.weight', 'h.6.crossattention.bias', 'h.10.crossattention.c_proj.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.weight', 'h.9.ln_cross_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.3.ln_cross_attn.weight', 'h.1.crossattention.q_attn.weight', 'h.10.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.weight', 'h.5.crossattention.c_proj.bias', 'h.7.ln_cross_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.bias', 'h.0.crossattention.bias', 'h.9.crossattention.c_attn.weight', 'h.1.ln_cross_attn.weight', 'h.8.crossattention.c_attn.weight', 'h.11.ln_cross_attn.weight', 'h.3.crossattention.c_attn.weight', 'h.10.crossattention.masked_bias', 'h.8.crossattention.c_proj.weight', 'h.2.crossattention.c_proj.weight', 'h.5.crossattention.c_proj.weight', 'h.7.crossattention.masked_bias', 'h.1.crossattention.c_proj.weight', 'h.4.crossattention.c_attn.weight', 'h.3.crossattention.masked_bias', 'h.5.crossattention.q_attn.weight', 'h.8.crossattention.bias', 'h.2.ln_cross_attn.weight', 'h.5.ln_cross_attn.weight', 'h.9.crossattention.bias', 'h.0.ln_cross_attn.weight', 'h.5.crossattention.bias', 'h.2.crossattention.q_attn.weight', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.4.crossattention.bias', 'h.0.crossattention.c_attn.weight', 'h.3.crossattention.bias', 'h.0.crossattention.q_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.11.crossattention.c_proj.bias', 'h.7.crossattention.bias', 'h.4.crossattention.masked_bias', 'h.6.crossattention.q_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.11.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.weight', 'h.2.crossattention.masked_bias', 'h.3.crossattention.q_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.5.crossattention.masked_bias', 'h.8.crossattention.masked_bias', 'h.8.crossattention.q_attn.weight', 'h.0.crossattention.masked_bias', 'h.7.crossattention.q_attn.weight', 'h.11.crossattention.c_attn.weight', 'h.1.crossattention.masked_bias', 'h.1.crossattention.c_attn.weight', 'h.6.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.weight', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.weight', 'h.2.crossattention.bias', 'h.7.crossattention.c_proj.weight', 'h.1.crossattention.c_proj.bias', 'h.6.crossattention.masked_bias', 'h.9.crossattention.c_proj.weight', 'h.10.crossattention.c_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBC44oAYLLV3",
        "outputId": "69282b3e-8b56-44af-ac75-7fa2a322c077"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Hyper-parameters: you could try playing with different settings\n",
        "num_epochs = 1\n",
        "learning_rate = 3e-5\n",
        "weight_decay = 1e-5\n",
        "eps = 1e-6\n",
        "batch_size = 1 #was 32\n",
        "warmup_rate = 0.05\n",
        "\n",
        "# Calculating the number of warmup steps\n",
        "num_training_cases = len(train_data)\n",
        "t_total = (num_training_cases // batch_size + 1) * num_epochs\n",
        "ext_warmup_steps = int(warmup_rate * t_total)\n",
        "\n",
        "# Initializing an AdamW optimizer\n",
        "ext_optim = torch.optim.AdamW(model.parameters(), lr=learning_rate,\n",
        "                              eps=eps, weight_decay=weight_decay)\n",
        "\n",
        "# Initializing the learning rate scheduler [details are in the BERT paper]\n",
        "ext_sche = transformers.get_linear_schedule_with_warmup(\n",
        "    ext_optim, num_warmup_steps=ext_warmup_steps, num_training_steps=t_total\n",
        ")\n",
        "\n",
        "print(\"***** Training Info *****\")\n",
        "print(\"  Num examples = %d\" % t_total)\n",
        "print(\"  Num Epochs = %d\" % num_epochs)\n",
        "print(\"  Batch size = %d\" % batch_size)\n",
        "print(\"  Total optimization steps = %d\" % t_total)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Training Info *****\n",
            "  Num examples = 14825\n",
            "  Num Epochs = 1\n",
            "  Batch size = 1\n",
            "  Total optimization steps = 14825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOvRGAUDLufu"
      },
      "source": [
        "def gather_batch(batch, full_text_key, label_key):\n",
        "\n",
        "    # input_batch  = [x[full_text_key] for x in batch if len(x[full_text_key]) < encoder_max_length]\n",
        "    input_batch  = [x[full_text_key] if len(x[full_text_key]) < encoder_max_length else x[full_text_key][:encoder_max_length] for x in batch]\n",
        "    label_batch  = [x[label_key] for x in batch]\n",
        "\n",
        "    return input_batch, label_batch"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2F9EKszcd02"
      },
      "source": [
        "def vectorize_batch(batch, tokenizer, full_text_key, label_key):\n",
        "    input_batch, label_batch = gather_batch(batch, full_text_key, label_key)\n",
        "\n",
        "    # Encode the main body\n",
        "    input_encode = tokenizer.batch_encode_plus(\n",
        "        input_batch,\n",
        "        max_length = encoder_max_length,\n",
        "        truncation = True,\n",
        "        padding = 'longest',\n",
        "        return_attention_mask = True,\n",
        "        return_tensors = 'pt'\n",
        "    )\n",
        "    input_ids = input_encode['input_ids'].to(device)\n",
        "\n",
        "    # Encode the summary\n",
        "    label_encode = tokenizer.batch_encode_plus(\n",
        "        label_batch,\n",
        "        max_length = decoder_max_length,\n",
        "        truncation = True,\n",
        "        padding = 'max_length',\n",
        "        return_attention_mask = True,\n",
        "        return_tensors = 'pt'\n",
        "    )\n",
        "    label_ids = label_encode['input_ids'].to(device)\n",
        "\n",
        "    return input_ids, label_ids"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehMkDafXMFlA",
        "outputId": "1a5fd60b-c2a0-4aee-91a9-838263cbcbfe"
      },
      "source": [
        "train_model = True\n",
        "\n",
        "loss_lst = []\n",
        "\n",
        "if train_model:\n",
        "\n",
        "  model.train()\n",
        "  max_grad_norm = 1\n",
        "\n",
        "  print(\"Number of Epochs\", num_epochs)\n",
        "  tot_steps = num_training_cases / batch_size\n",
        "  print(\"Total Training Steps\", tot_steps)\n",
        "  step_id = 0\n",
        "  perc_steps = tot_steps * 0.05\n",
        "  cur_step_displayed = 0\n",
        "  for _ in range(num_epochs):\n",
        "\n",
        "      random.shuffle(train_data)\n",
        "\n",
        "      for i in tqdm(range(0, num_training_cases, batch_size), position=0, leave=True):\n",
        "          batch = train_data[i: i + batch_size]\n",
        "          input_ids, label_ids = vectorize_batch(batch, tokenizer, full_text_key, label_key)\n",
        "\n",
        "          model.zero_grad()\n",
        "\n",
        "          outputs = model(input_ids=input_ids, labels=label_ids)\n",
        "\n",
        "          # Back-propagate the loss signal and clip the gradients\n",
        "          loss = outputs.loss.mean()\n",
        "          loss_lst.append(loss)\n",
        "          loss.backward()\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "\n",
        "          # Update neural network parameters and the learning rate\n",
        "          ext_optim.step()\n",
        "          ext_sche.step() # Update learning rate for better convergence\n",
        "\n",
        "\n",
        "          if step_id >= cur_step_displayed + perc_steps:\n",
        "              print(f'\\tAt step {step_id}, the extraction loss = {loss}')\n",
        "              cur_step_displayed += perc_steps\n",
        "          \n",
        "          step_id += 1\n",
        "\n",
        "  torch.save(model.state_dict(), MODEL_FOLDER+\"/\" + \"text_summarization_model_{}_{}_{}.pt\".format(wanted_data, pretrained_model_name, model_type))\n",
        "  print('Finished Training')\n",
        "\n",
        "else:\n",
        "  model.load_state_dict(torch.load(MODEL_FOLDER+\"/\" + \"text_summarization_model_{}_{}_{}.pt\".format(wanted_data, pretrained_model_name, model_type)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/14824 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of Epochs 1\n",
            "Total Training Steps 14824.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▌         | 743/14824 [02:47<53:46,  4.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 742, the extraction loss = -285.8289794921875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 1484/14824 [05:34<50:51,  4.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 1483, the extraction loss = -306.4549255371094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 2225/14824 [08:21<47:49,  4.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 2224, the extraction loss = -351.2602844238281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 2966/14824 [11:08<45:19,  4.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 2965, the extraction loss = -364.0935974121094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 3707/14824 [13:56<42:22,  4.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 3706, the extraction loss = -355.5331726074219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|███       | 4449/14824 [16:43<39:22,  4.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 4448, the extraction loss = -423.15289306640625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 5190/14824 [19:30<36:38,  4.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 5189, the extraction loss = -449.53253173828125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 5931/14824 [22:17<34:26,  4.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 5930, the extraction loss = -429.3357849121094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 6672/14824 [25:05<31:00,  4.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 6671, the extraction loss = -494.25244140625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 7413/14824 [27:52<28:13,  4.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 7412, the extraction loss = -450.6156005859375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 8155/14824 [30:40<25:24,  4.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 8154, the extraction loss = -513.306640625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 8896/14824 [33:28<22:39,  4.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 8895, the extraction loss = -510.73260498046875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 9637/14824 [36:16<19:53,  4.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 9636, the extraction loss = -573.5817260742188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 10378/14824 [39:04<17:04,  4.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 10377, the extraction loss = -508.3518371582031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 11120/14824 [41:53<14:11,  4.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 11119, the extraction loss = -609.3084106445312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 11861/14824 [44:41<11:17,  4.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 11860, the extraction loss = -524.7442626953125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 12602/14824 [47:29<08:31,  4.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 12601, the extraction loss = -513.1936645507812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 13343/14824 [50:17<05:41,  4.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 13342, the extraction loss = -601.949462890625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 14084/14824 [53:05<02:50,  4.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tAt step 14083, the extraction loss = -567.5281982421875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14824/14824 [55:53<00:00,  4.42it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwzLJ9JL220L"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "f = plt.figure(figsize=(10,5))\n",
        "plt.title(\"Extraction Loss at Training Step\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(loss_lst)\n",
        "plt.xticks(ticks=np.arange(0,len(loss_lst),10), labels=np.arange(0, len(loss_lst), 10)*100, rotation=30)\n",
        "f.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrBh9GZ5YY2k"
      },
      "source": [
        "## Evaluating our model using ROUGE and BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0X3zuxeaBy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de76ae7-5ccd-4b39-8515-d413618d515e"
      },
      "source": [
        "%%bash\n",
        "pip install sacrebleu\n",
        "pip install rouge_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2.0.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (0.12.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.19.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.2.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pfu5yx91AEY"
      },
      "source": [
        "PAD_INDEX = 0\n",
        "UNK_INDEX = 1\n",
        "SOS_INDEX = 2\n",
        "EOS_INDEX = 3\n",
        "def greedy_decode(batch_logits):\n",
        "  '''\n",
        "  decodes the logits in a greedy way, picks the most probable word till EOS token is found\n",
        "  logits: tensor, (batch_size x seq_len x vocab_size)\n",
        "  '''\n",
        "  batch_out_ids = torch.argmin(batch_logits, dim=2)\n",
        "  batch_predicted = []\n",
        "  for i in range(batch_out_ids.shape[0]):\n",
        "    out_ids = batch_out_ids[i] \n",
        "    out_ids_trunc = []\n",
        "    for id in out_ids:\n",
        "      if id == EOS_INDEX:\n",
        "        break\n",
        "      out_ids_trunc.append(id)\n",
        "    out_str = ' '.join(tokenizer.batch_decode(torch.stack(out_ids_trunc)))\n",
        "    batch_predicted.append(out_str)\n",
        "  return batch_predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOxDqA0IYfEv"
      },
      "source": [
        "import sacrebleu\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "rscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2'], use_stemmer=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POBZb6vCYfCU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "437ed5be-4763-44f1-df3e-9741e2afc55a"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "#redefining the keys to the bc3 dataset in case that wasnt trained on\n",
        "full_text_key = 'body'\n",
        "label_key = 'summary'\n",
        "\n",
        "rouge_scores_list = []\n",
        "bleu_score_list = []\n",
        "\n",
        "for i in tqdm(range(0, num_training_cases, batch_size), position=0, leave=True):\n",
        "  batch = test_data[i: i + batch_size]\n",
        "  input_batch  = [x[full_text_key] if len(x[full_text_key]) < encoder_max_length else x[full_text_key][:encoder_max_length] for x in batch]\n",
        "  label_batch  = [x[label_key] for x in batch]\n",
        "\n",
        "  input_encode = tokenizer.batch_encode_plus(\n",
        "      input_batch,\n",
        "      max_length = encoder_max_length,\n",
        "      truncation = True,\n",
        "      padding = 'longest',\n",
        "      return_attention_mask = True,\n",
        "      return_tensors = 'pt'\n",
        "  )\n",
        "  input_ids = input_encode['input_ids'].to(device)\n",
        "\n",
        "  # Encode the summary\n",
        "  label_encode = tokenizer.batch_encode_plus(\n",
        "      label_batch,\n",
        "      max_length = decoder_max_length,\n",
        "      truncation = True,\n",
        "      padding = 'max_length',\n",
        "      return_attention_mask = True,\n",
        "      return_tensors = 'pt'\n",
        "  )\n",
        "  label_ids = label_encode['input_ids'].to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(input_ids=input_ids, labels=label_ids)\n",
        "\n",
        "  pred_batch = greedy_decode(outputs.logits)\n",
        "  rouge_scores_list.extend([rscorer.score(targ, pred) for targ, pred in zip(label_batch, pred_batch)])\n",
        "  bleu_score_list.extend([sacrebleu.raw_corpus_bleu([pred], [[targ]], .01).score for pred, targ in zip(pred_batch, label_batch)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|▏         | 26/1853 [00:22<20:40,  1.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-306607d4ca15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'longest'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mreturn_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m   )\n\u001b[1;32m     23\u001b[0m   \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_encode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2454\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2455\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2456\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2457\u001b[0m         )\n\u001b[1;32m   2458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# we add an overflow_to_sample_mapping array (see below)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0msanitized_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_and_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m             \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_and_encodings\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0msanitized_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZLR9pmaYe_g"
      },
      "source": [
        "print(np.mean([sc['rouge2'].fmeasure for sc in rouge_scores_list]))\n",
        "print(np.mean([sc['rouge1'].fmeasure for sc in rouge_scores_list]))\n",
        "print(np.mean(bleu_score_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rytkkp2SOHDU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}